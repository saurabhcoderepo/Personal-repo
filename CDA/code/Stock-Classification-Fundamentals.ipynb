{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d623077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635595e",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b27f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06adde54e4f3434582d5b23baf6b20ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "fundamentals = pd.read_csv('../data/stocks_data_fundamentals.csv',index_col=0, parse_dates=True)\n",
    "\n",
    "fundamentals['dates'] = pd.to_datetime(fundamentals['dates'],format='%b %y')\n",
    "\n",
    "stocks = fundamentals['stocks'].unique()\n",
    "\n",
    "for stock in tqdm(stocks):\n",
    "    \n",
    "    df = fundamentals.loc[fundamentals['stocks'] == stock]\n",
    "    df.replace(0,df.median(axis=1),inplace=True)\n",
    "    fundamentals.loc[df.index, :] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9329f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stocks</th>\n",
       "      <th>dates</th>\n",
       "      <th>BasicEPS</th>\n",
       "      <th>DilutedEPS</th>\n",
       "      <th>CashEPS</th>\n",
       "      <th>DivPS</th>\n",
       "      <th>OpRev</th>\n",
       "      <th>NPS</th>\n",
       "      <th>ROCE</th>\n",
       "      <th>NPMargin</th>\n",
       "      <th>...</th>\n",
       "      <th>ROE2Networth</th>\n",
       "      <th>EntValue</th>\n",
       "      <th>EntValuePerNetSales</th>\n",
       "      <th>Price2Book</th>\n",
       "      <th>Price2Sales</th>\n",
       "      <th>RetentionRatios</th>\n",
       "      <th>EarningYield</th>\n",
       "      <th>AssetTurnRatio</th>\n",
       "      <th>EVPerEBITDA</th>\n",
       "      <th>PBDITMargin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>22.87</td>\n",
       "      <td>22.87</td>\n",
       "      <td>26.59</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.10</td>\n",
       "      <td>22.87</td>\n",
       "      <td>1.64</td>\n",
       "      <td>7.69</td>\n",
       "      <td>...</td>\n",
       "      <td>8.86</td>\n",
       "      <td>4210541.48</td>\n",
       "      <td>15.88</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.23</td>\n",
       "      <td>82.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>16.23</td>\n",
       "      <td>16.23</td>\n",
       "      <td>19.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>288.33</td>\n",
       "      <td>16.23</td>\n",
       "      <td>1.79</td>\n",
       "      <td>5.63</td>\n",
       "      <td>...</td>\n",
       "      <td>6.95</td>\n",
       "      <td>3565310.84</td>\n",
       "      <td>13.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.68</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.13</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>3423771.88</td>\n",
       "      <td>14.10</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.18</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>-7.67</td>\n",
       "      <td>-7.67</td>\n",
       "      <td>-4.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>247.07</td>\n",
       "      <td>-7.34</td>\n",
       "      <td>1.81</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.37</td>\n",
       "      <td>3141292.12</td>\n",
       "      <td>14.25</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.01</td>\n",
       "      <td>100.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>13.43</td>\n",
       "      <td>13.43</td>\n",
       "      <td>16.02</td>\n",
       "      <td>2.6</td>\n",
       "      <td>220.13</td>\n",
       "      <td>13.15</td>\n",
       "      <td>1.99</td>\n",
       "      <td>5.97</td>\n",
       "      <td>...</td>\n",
       "      <td>6.69</td>\n",
       "      <td>2467752.16</td>\n",
       "      <td>14.06</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.33</td>\n",
       "      <td>79.88</td>\n",
       "      <td>0.04</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>HEROMOTOCO</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>156.86</td>\n",
       "      <td>156.86</td>\n",
       "      <td>178.96</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1432.11</td>\n",
       "      <td>156.85</td>\n",
       "      <td>37.77</td>\n",
       "      <td>10.95</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>58648.34</td>\n",
       "      <td>2.05</td>\n",
       "      <td>7.40</td>\n",
       "      <td>2.06</td>\n",
       "      <td>54.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>231.74</td>\n",
       "      <td>12.12</td>\n",
       "      <td>16.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>HEROMOTOCO</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>119.46</td>\n",
       "      <td>119.46</td>\n",
       "      <td>146.50</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1381.34</td>\n",
       "      <td>119.46</td>\n",
       "      <td>35.93</td>\n",
       "      <td>8.64</td>\n",
       "      <td>...</td>\n",
       "      <td>36.47</td>\n",
       "      <td>52613.47</td>\n",
       "      <td>1.91</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1.91</td>\n",
       "      <td>49.77</td>\n",
       "      <td>0.05</td>\n",
       "      <td>262.17</td>\n",
       "      <td>13.04</td>\n",
       "      <td>14.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>HEROMOTOCO</td>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>105.61</td>\n",
       "      <td>105.61</td>\n",
       "      <td>161.06</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1265.67</td>\n",
       "      <td>105.61</td>\n",
       "      <td>37.16</td>\n",
       "      <td>8.34</td>\n",
       "      <td>...</td>\n",
       "      <td>37.66</td>\n",
       "      <td>45271.31</td>\n",
       "      <td>1.79</td>\n",
       "      <td>8.11</td>\n",
       "      <td>1.80</td>\n",
       "      <td>38.40</td>\n",
       "      <td>0.05</td>\n",
       "      <td>250.31</td>\n",
       "      <td>11.36</td>\n",
       "      <td>15.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>HEROMOTOCO</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>106.07</td>\n",
       "      <td>106.07</td>\n",
       "      <td>163.24</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1190.19</td>\n",
       "      <td>106.07</td>\n",
       "      <td>38.71</td>\n",
       "      <td>8.91</td>\n",
       "      <td>...</td>\n",
       "      <td>42.31</td>\n",
       "      <td>30912.86</td>\n",
       "      <td>1.30</td>\n",
       "      <td>6.15</td>\n",
       "      <td>1.30</td>\n",
       "      <td>43.43</td>\n",
       "      <td>0.07</td>\n",
       "      <td>246.51</td>\n",
       "      <td>8.39</td>\n",
       "      <td>15.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>HEROMOTOCO</td>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>119.09</td>\n",
       "      <td>119.09</td>\n",
       "      <td>174.03</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1180.72</td>\n",
       "      <td>119.09</td>\n",
       "      <td>42.86</td>\n",
       "      <td>10.08</td>\n",
       "      <td>...</td>\n",
       "      <td>55.43</td>\n",
       "      <td>41969.92</td>\n",
       "      <td>1.78</td>\n",
       "      <td>9.57</td>\n",
       "      <td>1.74</td>\n",
       "      <td>62.21</td>\n",
       "      <td>0.06</td>\n",
       "      <td>238.43</td>\n",
       "      <td>10.54</td>\n",
       "      <td>16.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         stocks      dates  BasicEPS  DilutedEPS  CashEPS  DivPS    OpRev  \\\n",
       "0           SBI 2021-03-01     22.87       22.87    26.59    4.0   297.10   \n",
       "1           SBI 2020-03-01     16.23       16.23    19.94    0.0   288.33   \n",
       "2           SBI 2019-03-01      0.97        0.97     0.97    0.0   272.13   \n",
       "3           SBI 2018-03-01     -7.67       -7.67    -4.07    0.0   247.07   \n",
       "4           SBI 2017-03-01     13.43       13.43    16.02    2.6   220.13   \n",
       "..          ...        ...       ...         ...      ...    ...      ...   \n",
       "495  HEROMOTOCO 2016-03-01    156.86      156.86   178.96   72.0  1432.11   \n",
       "496  HEROMOTOCO 2015-03-01    119.46      119.46   146.50   60.0  1381.34   \n",
       "497  HEROMOTOCO 2014-03-01    105.61      105.61   161.06   65.0  1265.67   \n",
       "498  HEROMOTOCO 2013-03-01    106.07      106.07   163.24   60.0  1190.19   \n",
       "499  HEROMOTOCO 2012-03-01    119.09      119.09   174.03   45.0  1180.72   \n",
       "\n",
       "        NPS   ROCE  NPMargin  ...  ROE2Networth    EntValue  \\\n",
       "0     22.87   1.64      7.69  ...          8.86  4210541.48   \n",
       "1     16.23   1.79      5.63  ...          6.95  3565310.84   \n",
       "2      0.97   0.00      0.35  ...          0.39  3423771.88   \n",
       "3     -7.34   1.81     -2.96  ...         -3.37  3141292.12   \n",
       "4     13.15   1.99      5.97  ...          6.69  2467752.16   \n",
       "..      ...    ...       ...  ...           ...         ...   \n",
       "495  156.85  37.77     10.95  ...         39.42    58648.34   \n",
       "496  119.46  35.93      8.64  ...         36.47    52613.47   \n",
       "497  105.61  37.16      8.34  ...         37.66    45271.31   \n",
       "498  106.07  38.71      8.91  ...         42.31    30912.86   \n",
       "499  119.09  42.86     10.08  ...         55.43    41969.92   \n",
       "\n",
       "     EntValuePerNetSales  Price2Book  Price2Sales  RetentionRatios  \\\n",
       "0                  15.88        1.41         1.23            82.50   \n",
       "1                  13.86        0.84         0.68           100.00   \n",
       "2                  14.10        1.30         1.18           100.00   \n",
       "3                  14.25        1.15         1.01           100.00   \n",
       "4                  14.06        1.49         1.33            79.88   \n",
       "..                   ...         ...          ...              ...   \n",
       "495                 2.05        7.40         2.06            54.10   \n",
       "496                 1.91        8.07         1.91            49.77   \n",
       "497                 1.79        8.11         1.80            38.40   \n",
       "498                 1.30        6.15         1.30            43.43   \n",
       "499                 1.78        9.57         1.74            62.21   \n",
       "\n",
       "     EarningYield  AssetTurnRatio EVPerEBITDA PBDITMargin  \n",
       "0            0.06             ---         ---         ---  \n",
       "1            0.08             ---         ---         ---  \n",
       "2            0.00             ---         ---         ---  \n",
       "3           -0.03             ---         ---         ---  \n",
       "4            0.04             ---         ---         ---  \n",
       "..            ...             ...         ...         ...  \n",
       "495          0.05          231.74       12.12       16.91  \n",
       "496          0.05          262.17       13.04       14.62  \n",
       "497          0.05          250.31       11.36       15.77  \n",
       "498          0.07          246.51        8.39       15.49  \n",
       "499          0.06          238.43       10.54       16.89  \n",
       "\n",
       "[500 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f2e358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7959a_row0_col0, #T_7959a_row0_col1, #T_7959a_row1_col0, #T_7959a_row1_col1, #T_7959a_row2_col2, #T_7959a_row3_col3, #T_7959a_row4_col4, #T_7959a_row5_col5, #T_7959a_row6_col6, #T_7959a_row7_col7, #T_7959a_row8_col8, #T_7959a_row9_col9, #T_7959a_row10_col10, #T_7959a_row11_col11, #T_7959a_row11_col13, #T_7959a_row12_col12, #T_7959a_row13_col11, #T_7959a_row13_col13, #T_7959a_row14_col14, #T_7959a_row15_col15 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row0_col2, #T_7959a_row1_col2, #T_7959a_row2_col0, #T_7959a_row2_col1 {\n",
       "  background-color: #c73635;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row0_col3 {\n",
       "  background-color: #f7b599;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row0_col4, #T_7959a_row1_col4, #T_7959a_row4_col5 {\n",
       "  background-color: #f59d7e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row0_col5, #T_7959a_row1_col5, #T_7959a_row5_col0, #T_7959a_row5_col1 {\n",
       "  background-color: #b8122a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row0_col6, #T_7959a_row1_col6, #T_7959a_row8_col15, #T_7959a_row9_col15 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row0_col7, #T_7959a_row1_col7, #T_7959a_row5_col7, #T_7959a_row7_col4, #T_7959a_row13_col14, #T_7959a_row14_col13 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row0_col8 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row0_col9, #T_7959a_row1_col9 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row0_col10, #T_7959a_row1_col10, #T_7959a_row5_col10, #T_7959a_row13_col3 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row0_col11, #T_7959a_row1_col11, #T_7959a_row5_col11, #T_7959a_row14_col8 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row0_col12, #T_7959a_row1_col12 {\n",
       "  background-color: #a3c2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row0_col13, #T_7959a_row1_col13, #T_7959a_row4_col10, #T_7959a_row5_col13, #T_7959a_row9_col10, #T_7959a_row14_col11 {\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row0_col14, #T_7959a_row1_col14, #T_7959a_row4_col14, #T_7959a_row11_col10 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row0_col15, #T_7959a_row1_col15, #T_7959a_row15_col8 {\n",
       "  background-color: #90b2fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row1_col3 {\n",
       "  background-color: #f7b497;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row1_col8, #T_7959a_row5_col6 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row2_col3, #T_7959a_row3_col2 {\n",
       "  background-color: #f6bfa6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row2_col4 {\n",
       "  background-color: #ef886b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row2_col5, #T_7959a_row5_col2 {\n",
       "  background-color: #c32e31;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row2_col6, #T_7959a_row7_col15, #T_7959a_row14_col15 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row2_col7, #T_7959a_row9_col14 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row2_col8, #T_7959a_row4_col15 {\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row2_col9, #T_7959a_row6_col4, #T_7959a_row10_col15, #T_7959a_row12_col0, #T_7959a_row12_col1 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row2_col10 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row2_col11, #T_7959a_row2_col13, #T_7959a_row7_col14, #T_7959a_row11_col14 {\n",
       "  background-color: #465ecf;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row2_col12, #T_7959a_row6_col0, #T_7959a_row6_col1, #T_7959a_row8_col0, #T_7959a_row8_col1 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row2_col14, #T_7959a_row4_col9, #T_7959a_row5_col14, #T_7959a_row14_col12, #T_7959a_row15_col1 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row2_col15, #T_7959a_row4_col12 {\n",
       "  background-color: #88abfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row3_col0, #T_7959a_row3_col1 {\n",
       "  background-color: #f7b79b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row3_col4 {\n",
       "  background-color: #edd2c3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row3_col5 {\n",
       "  background-color: #f7b396;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row3_col6 {\n",
       "  background-color: #e0dbd8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row3_col7, #T_7959a_row14_col0, #T_7959a_row15_col3 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row3_col8 {\n",
       "  background-color: #d5dbe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row3_col9, #T_7959a_row9_col3 {\n",
       "  background-color: #d8dce2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row3_col10, #T_7959a_row10_col7, #T_7959a_row11_col3 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row3_col11, #T_7959a_row7_col3, #T_7959a_row14_col5 {\n",
       "  background-color: #5875e1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row3_col12, #T_7959a_row7_col8 {\n",
       "  background-color: #f2cab5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row3_col13 {\n",
       "  background-color: #5977e3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row3_col14, #T_7959a_row7_col0, #T_7959a_row7_col1, #T_7959a_row7_col5, #T_7959a_row8_col14, #T_7959a_row12_col14 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row3_col15, #T_7959a_row11_col15, #T_7959a_row13_col15 {\n",
       "  background-color: #80a3fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row4_col0, #T_7959a_row4_col1 {\n",
       "  background-color: #f6a283;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row4_col2 {\n",
       "  background-color: #f08b6e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row4_col3 {\n",
       "  background-color: #ead4c8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row4_col6, #T_7959a_row15_col4 {\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row4_col7, #T_7959a_row4_col11, #T_7959a_row4_col13, #T_7959a_row6_col14, #T_7959a_row8_col10, #T_7959a_row10_col2, #T_7959a_row10_col6, #T_7959a_row10_col8, #T_7959a_row10_col9, #T_7959a_row11_col0, #T_7959a_row11_col1, #T_7959a_row11_col4, #T_7959a_row11_col5, #T_7959a_row12_col15, #T_7959a_row14_col3, #T_7959a_row15_col12 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row4_col8 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row5_col3 {\n",
       "  background-color: #f7b093;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row5_col4 {\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row5_col8, #T_7959a_row11_col12, #T_7959a_row13_col12 {\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row5_col9, #T_7959a_row5_col15, #T_7959a_row12_col11, #T_7959a_row12_col13 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row5_col12 {\n",
       "  background-color: #a5c3fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row6_col2, #T_7959a_row8_col2, #T_7959a_row9_col0, #T_7959a_row9_col1 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row6_col3 {\n",
       "  background-color: #dbdcde;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row6_col5 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row6_col7 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row6_col8, #T_7959a_row8_col6 {\n",
       "  background-color: #d24b40;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row6_col9 {\n",
       "  background-color: #da5a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row6_col10, #T_7959a_row10_col0, #T_7959a_row10_col1, #T_7959a_row10_col5, #T_7959a_row13_col2, #T_7959a_row14_col7 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row6_col11 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row6_col12 {\n",
       "  background-color: #f7af91;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row6_col13 {\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row6_col15 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row7_col2, #T_7959a_row10_col4 {\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row7_col6 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row7_col9 {\n",
       "  background-color: #cedaeb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row7_col10, #T_7959a_row15_col2, #T_7959a_row15_col13 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row7_col11, #T_7959a_row7_col13 {\n",
       "  background-color: #d75445;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row7_col12 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row8_col3, #T_7959a_row9_col7 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row8_col4, #T_7959a_row15_col6, #T_7959a_row15_col7 {\n",
       "  background-color: #6e90f2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row8_col5 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row8_col7 {\n",
       "  background-color: #efcfbf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row8_col9 {\n",
       "  background-color: #e67259;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row8_col11 {\n",
       "  background-color: #e2dad5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row8_col12 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row8_col13, #T_7959a_row11_col8 {\n",
       "  background-color: #e5d8d1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row9_col2, #T_7959a_row15_col14 {\n",
       "  background-color: #779af7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row9_col4, #T_7959a_row10_col12 {\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row9_col5 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row9_col6 {\n",
       "  background-color: #d95847;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row9_col8 {\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row9_col11 {\n",
       "  background-color: #bed2f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row9_col12 {\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row9_col13 {\n",
       "  background-color: #bfd3f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row10_col3, #T_7959a_row14_col6, #T_7959a_row14_col9 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row10_col11 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row10_col13 {\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row10_col14 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row11_col2, #T_7959a_row13_col0, #T_7959a_row13_col1, #T_7959a_row13_col4, #T_7959a_row13_col5 {\n",
       "  background-color: #3c4ec2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row11_col6 {\n",
       "  background-color: #b3cdfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row11_col7, #T_7959a_row13_col7 {\n",
       "  background-color: #d85646;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row11_col9 {\n",
       "  background-color: #b7cff9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row12_col2 {\n",
       "  background-color: #7295f4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row12_col3 {\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row12_col4 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row12_col5 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row12_col6 {\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row12_col7, #T_7959a_row14_col4, #T_7959a_row15_col0 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row12_col8 {\n",
       "  background-color: #dedcdb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row12_col9 {\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row12_col10 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row13_col6 {\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row13_col8 {\n",
       "  background-color: #e8d6cc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row13_col9 {\n",
       "  background-color: #bbd1f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_7959a_row13_col10, #T_7959a_row14_col2 {\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row14_col1 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row14_col10 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row15_col5 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row15_col9 {\n",
       "  background-color: #82a6fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_7959a_row15_col10, #T_7959a_row15_col11 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7959a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7959a_level0_col0\" class=\"col_heading level0 col0\" >BasicEPS</th>\n",
       "      <th id=\"T_7959a_level0_col1\" class=\"col_heading level0 col1\" >DilutedEPS</th>\n",
       "      <th id=\"T_7959a_level0_col2\" class=\"col_heading level0 col2\" >CashEPS</th>\n",
       "      <th id=\"T_7959a_level0_col3\" class=\"col_heading level0 col3\" >DivPS</th>\n",
       "      <th id=\"T_7959a_level0_col4\" class=\"col_heading level0 col4\" >OpRev</th>\n",
       "      <th id=\"T_7959a_level0_col5\" class=\"col_heading level0 col5\" >NPS</th>\n",
       "      <th id=\"T_7959a_level0_col6\" class=\"col_heading level0 col6\" >ROCE</th>\n",
       "      <th id=\"T_7959a_level0_col7\" class=\"col_heading level0 col7\" >NPMargin</th>\n",
       "      <th id=\"T_7959a_level0_col8\" class=\"col_heading level0 col8\" >ROA</th>\n",
       "      <th id=\"T_7959a_level0_col9\" class=\"col_heading level0 col9\" >ROE2Networth</th>\n",
       "      <th id=\"T_7959a_level0_col10\" class=\"col_heading level0 col10\" >EntValue</th>\n",
       "      <th id=\"T_7959a_level0_col11\" class=\"col_heading level0 col11\" >EntValuePerNetSales</th>\n",
       "      <th id=\"T_7959a_level0_col12\" class=\"col_heading level0 col12\" >Price2Book</th>\n",
       "      <th id=\"T_7959a_level0_col13\" class=\"col_heading level0 col13\" >Price2Sales</th>\n",
       "      <th id=\"T_7959a_level0_col14\" class=\"col_heading level0 col14\" >RetentionRatios</th>\n",
       "      <th id=\"T_7959a_level0_col15\" class=\"col_heading level0 col15\" >EarningYield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row0\" class=\"row_heading level0 row0\" >BasicEPS</th>\n",
       "      <td id=\"T_7959a_row0_col0\" class=\"data row0 col0\" >1.000</td>\n",
       "      <td id=\"T_7959a_row0_col1\" class=\"data row0 col1\" >1.000</td>\n",
       "      <td id=\"T_7959a_row0_col2\" class=\"data row0 col2\" >0.943</td>\n",
       "      <td id=\"T_7959a_row0_col3\" class=\"data row0 col3\" >0.646</td>\n",
       "      <td id=\"T_7959a_row0_col4\" class=\"data row0 col4\" >0.706</td>\n",
       "      <td id=\"T_7959a_row0_col5\" class=\"data row0 col5\" >0.985</td>\n",
       "      <td id=\"T_7959a_row0_col6\" class=\"data row0 col6\" >0.233</td>\n",
       "      <td id=\"T_7959a_row0_col7\" class=\"data row0 col7\" >-0.046</td>\n",
       "      <td id=\"T_7959a_row0_col8\" class=\"data row0 col8\" >0.233</td>\n",
       "      <td id=\"T_7959a_row0_col9\" class=\"data row0 col9\" >0.184</td>\n",
       "      <td id=\"T_7959a_row0_col10\" class=\"data row0 col10\" >-0.066</td>\n",
       "      <td id=\"T_7959a_row0_col11\" class=\"data row0 col11\" >-0.075</td>\n",
       "      <td id=\"T_7959a_row0_col12\" class=\"data row0 col12\" >0.137</td>\n",
       "      <td id=\"T_7959a_row0_col13\" class=\"data row0 col13\" >-0.070</td>\n",
       "      <td id=\"T_7959a_row0_col14\" class=\"data row0 col14\" >0.022</td>\n",
       "      <td id=\"T_7959a_row0_col15\" class=\"data row0 col15\" >0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row1\" class=\"row_heading level0 row1\" >DilutedEPS</th>\n",
       "      <td id=\"T_7959a_row1_col0\" class=\"data row1 col0\" >1.000</td>\n",
       "      <td id=\"T_7959a_row1_col1\" class=\"data row1 col1\" >1.000</td>\n",
       "      <td id=\"T_7959a_row1_col2\" class=\"data row1 col2\" >0.943</td>\n",
       "      <td id=\"T_7959a_row1_col3\" class=\"data row1 col3\" >0.647</td>\n",
       "      <td id=\"T_7959a_row1_col4\" class=\"data row1 col4\" >0.707</td>\n",
       "      <td id=\"T_7959a_row1_col5\" class=\"data row1 col5\" >0.985</td>\n",
       "      <td id=\"T_7959a_row1_col6\" class=\"data row1 col6\" >0.233</td>\n",
       "      <td id=\"T_7959a_row1_col7\" class=\"data row1 col7\" >-0.046</td>\n",
       "      <td id=\"T_7959a_row1_col8\" class=\"data row1 col8\" >0.233</td>\n",
       "      <td id=\"T_7959a_row1_col9\" class=\"data row1 col9\" >0.184</td>\n",
       "      <td id=\"T_7959a_row1_col10\" class=\"data row1 col10\" >-0.066</td>\n",
       "      <td id=\"T_7959a_row1_col11\" class=\"data row1 col11\" >-0.074</td>\n",
       "      <td id=\"T_7959a_row1_col12\" class=\"data row1 col12\" >0.137</td>\n",
       "      <td id=\"T_7959a_row1_col13\" class=\"data row1 col13\" >-0.070</td>\n",
       "      <td id=\"T_7959a_row1_col14\" class=\"data row1 col14\" >0.022</td>\n",
       "      <td id=\"T_7959a_row1_col15\" class=\"data row1 col15\" >0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row2\" class=\"row_heading level0 row2\" >CashEPS</th>\n",
       "      <td id=\"T_7959a_row2_col0\" class=\"data row2 col0\" >0.943</td>\n",
       "      <td id=\"T_7959a_row2_col1\" class=\"data row2 col1\" >0.943</td>\n",
       "      <td id=\"T_7959a_row2_col2\" class=\"data row2 col2\" >1.000</td>\n",
       "      <td id=\"T_7959a_row2_col3\" class=\"data row2 col3\" >0.610</td>\n",
       "      <td id=\"T_7959a_row2_col4\" class=\"data row2 col4\" >0.766</td>\n",
       "      <td id=\"T_7959a_row2_col5\" class=\"data row2 col5\" >0.957</td>\n",
       "      <td id=\"T_7959a_row2_col6\" class=\"data row2 col6\" >0.176</td>\n",
       "      <td id=\"T_7959a_row2_col7\" class=\"data row2 col7\" >-0.052</td>\n",
       "      <td id=\"T_7959a_row2_col8\" class=\"data row2 col8\" >0.176</td>\n",
       "      <td id=\"T_7959a_row2_col9\" class=\"data row2 col9\" >0.120</td>\n",
       "      <td id=\"T_7959a_row2_col10\" class=\"data row2 col10\" >-0.086</td>\n",
       "      <td id=\"T_7959a_row2_col11\" class=\"data row2 col11\" >-0.081</td>\n",
       "      <td id=\"T_7959a_row2_col12\" class=\"data row2 col12\" >0.101</td>\n",
       "      <td id=\"T_7959a_row2_col13\" class=\"data row2 col13\" >-0.076</td>\n",
       "      <td id=\"T_7959a_row2_col14\" class=\"data row2 col14\" >0.026</td>\n",
       "      <td id=\"T_7959a_row2_col15\" class=\"data row2 col15\" >0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row3\" class=\"row_heading level0 row3\" >DivPS</th>\n",
       "      <td id=\"T_7959a_row3_col0\" class=\"data row3 col0\" >0.646</td>\n",
       "      <td id=\"T_7959a_row3_col1\" class=\"data row3 col1\" >0.647</td>\n",
       "      <td id=\"T_7959a_row3_col2\" class=\"data row3 col2\" >0.610</td>\n",
       "      <td id=\"T_7959a_row3_col3\" class=\"data row3 col3\" >1.000</td>\n",
       "      <td id=\"T_7959a_row3_col4\" class=\"data row3 col4\" >0.515</td>\n",
       "      <td id=\"T_7959a_row3_col5\" class=\"data row3 col5\" >0.659</td>\n",
       "      <td id=\"T_7959a_row3_col6\" class=\"data row3 col6\" >0.447</td>\n",
       "      <td id=\"T_7959a_row3_col7\" class=\"data row3 col7\" >0.012</td>\n",
       "      <td id=\"T_7959a_row3_col8\" class=\"data row3 col8\" >0.392</td>\n",
       "      <td id=\"T_7959a_row3_col9\" class=\"data row3 col9\" >0.435</td>\n",
       "      <td id=\"T_7959a_row3_col10\" class=\"data row3 col10\" >-0.076</td>\n",
       "      <td id=\"T_7959a_row3_col11\" class=\"data row3 col11\" >-0.019</td>\n",
       "      <td id=\"T_7959a_row3_col12\" class=\"data row3 col12\" >0.501</td>\n",
       "      <td id=\"T_7959a_row3_col13\" class=\"data row3 col13\" >-0.010</td>\n",
       "      <td id=\"T_7959a_row3_col14\" class=\"data row3 col14\" >-0.091</td>\n",
       "      <td id=\"T_7959a_row3_col15\" class=\"data row3 col15\" >0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row4\" class=\"row_heading level0 row4\" >OpRev</th>\n",
       "      <td id=\"T_7959a_row4_col0\" class=\"data row4 col0\" >0.706</td>\n",
       "      <td id=\"T_7959a_row4_col1\" class=\"data row4 col1\" >0.707</td>\n",
       "      <td id=\"T_7959a_row4_col2\" class=\"data row4 col2\" >0.766</td>\n",
       "      <td id=\"T_7959a_row4_col3\" class=\"data row4 col3\" >0.515</td>\n",
       "      <td id=\"T_7959a_row4_col4\" class=\"data row4 col4\" >1.000</td>\n",
       "      <td id=\"T_7959a_row4_col5\" class=\"data row4 col5\" >0.722</td>\n",
       "      <td id=\"T_7959a_row4_col6\" class=\"data row4 col6\" >0.094</td>\n",
       "      <td id=\"T_7959a_row4_col7\" class=\"data row4 col7\" >-0.087</td>\n",
       "      <td id=\"T_7959a_row4_col8\" class=\"data row4 col8\" >0.055</td>\n",
       "      <td id=\"T_7959a_row4_col9\" class=\"data row4 col9\" >0.049</td>\n",
       "      <td id=\"T_7959a_row4_col10\" class=\"data row4 col10\" >-0.095</td>\n",
       "      <td id=\"T_7959a_row4_col11\" class=\"data row4 col11\" >-0.128</td>\n",
       "      <td id=\"T_7959a_row4_col12\" class=\"data row4 col12\" >0.038</td>\n",
       "      <td id=\"T_7959a_row4_col13\" class=\"data row4 col13\" >-0.120</td>\n",
       "      <td id=\"T_7959a_row4_col14\" class=\"data row4 col14\" >0.023</td>\n",
       "      <td id=\"T_7959a_row4_col15\" class=\"data row4 col15\" >0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row5\" class=\"row_heading level0 row5\" >NPS</th>\n",
       "      <td id=\"T_7959a_row5_col0\" class=\"data row5 col0\" >0.985</td>\n",
       "      <td id=\"T_7959a_row5_col1\" class=\"data row5 col1\" >0.985</td>\n",
       "      <td id=\"T_7959a_row5_col2\" class=\"data row5 col2\" >0.957</td>\n",
       "      <td id=\"T_7959a_row5_col3\" class=\"data row5 col3\" >0.659</td>\n",
       "      <td id=\"T_7959a_row5_col4\" class=\"data row5 col4\" >0.722</td>\n",
       "      <td id=\"T_7959a_row5_col5\" class=\"data row5 col5\" >1.000</td>\n",
       "      <td id=\"T_7959a_row5_col6\" class=\"data row5 col6\" >0.245</td>\n",
       "      <td id=\"T_7959a_row5_col7\" class=\"data row5 col7\" >-0.046</td>\n",
       "      <td id=\"T_7959a_row5_col8\" class=\"data row5 col8\" >0.244</td>\n",
       "      <td id=\"T_7959a_row5_col9\" class=\"data row5 col9\" >0.193</td>\n",
       "      <td id=\"T_7959a_row5_col10\" class=\"data row5 col10\" >-0.063</td>\n",
       "      <td id=\"T_7959a_row5_col11\" class=\"data row5 col11\" >-0.074</td>\n",
       "      <td id=\"T_7959a_row5_col12\" class=\"data row5 col12\" >0.144</td>\n",
       "      <td id=\"T_7959a_row5_col13\" class=\"data row5 col13\" >-0.069</td>\n",
       "      <td id=\"T_7959a_row5_col14\" class=\"data row5 col14\" >0.027</td>\n",
       "      <td id=\"T_7959a_row5_col15\" class=\"data row5 col15\" >0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row6\" class=\"row_heading level0 row6\" >ROCE</th>\n",
       "      <td id=\"T_7959a_row6_col0\" class=\"data row6 col0\" >0.233</td>\n",
       "      <td id=\"T_7959a_row6_col1\" class=\"data row6 col1\" >0.233</td>\n",
       "      <td id=\"T_7959a_row6_col2\" class=\"data row6 col2\" >0.176</td>\n",
       "      <td id=\"T_7959a_row6_col3\" class=\"data row6 col3\" >0.447</td>\n",
       "      <td id=\"T_7959a_row6_col4\" class=\"data row6 col4\" >0.094</td>\n",
       "      <td id=\"T_7959a_row6_col5\" class=\"data row6 col5\" >0.245</td>\n",
       "      <td id=\"T_7959a_row6_col6\" class=\"data row6 col6\" >1.000</td>\n",
       "      <td id=\"T_7959a_row6_col7\" class=\"data row6 col7\" >0.348</td>\n",
       "      <td id=\"T_7959a_row6_col8\" class=\"data row6 col8\" >0.900</td>\n",
       "      <td id=\"T_7959a_row6_col9\" class=\"data row6 col9\" >0.874</td>\n",
       "      <td id=\"T_7959a_row6_col10\" class=\"data row6 col10\" >-0.135</td>\n",
       "      <td id=\"T_7959a_row6_col11\" class=\"data row6 col11\" >0.277</td>\n",
       "      <td id=\"T_7959a_row6_col12\" class=\"data row6 col12\" >0.614</td>\n",
       "      <td id=\"T_7959a_row6_col13\" class=\"data row6 col13\" >0.294</td>\n",
       "      <td id=\"T_7959a_row6_col14\" class=\"data row6 col14\" >-0.121</td>\n",
       "      <td id=\"T_7959a_row6_col15\" class=\"data row6 col15\" >0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row7\" class=\"row_heading level0 row7\" >NPMargin</th>\n",
       "      <td id=\"T_7959a_row7_col0\" class=\"data row7 col0\" >-0.046</td>\n",
       "      <td id=\"T_7959a_row7_col1\" class=\"data row7 col1\" >-0.046</td>\n",
       "      <td id=\"T_7959a_row7_col2\" class=\"data row7 col2\" >-0.052</td>\n",
       "      <td id=\"T_7959a_row7_col3\" class=\"data row7 col3\" >0.012</td>\n",
       "      <td id=\"T_7959a_row7_col4\" class=\"data row7 col4\" >-0.087</td>\n",
       "      <td id=\"T_7959a_row7_col5\" class=\"data row7 col5\" >-0.046</td>\n",
       "      <td id=\"T_7959a_row7_col6\" class=\"data row7 col6\" >0.348</td>\n",
       "      <td id=\"T_7959a_row7_col7\" class=\"data row7 col7\" >1.000</td>\n",
       "      <td id=\"T_7959a_row7_col8\" class=\"data row7 col8\" >0.545</td>\n",
       "      <td id=\"T_7959a_row7_col9\" class=\"data row7 col9\" >0.395</td>\n",
       "      <td id=\"T_7959a_row7_col10\" class=\"data row7 col10\" >-0.018</td>\n",
       "      <td id=\"T_7959a_row7_col11\" class=\"data row7 col11\" >0.883</td>\n",
       "      <td id=\"T_7959a_row7_col12\" class=\"data row7 col12\" >0.058</td>\n",
       "      <td id=\"T_7959a_row7_col13\" class=\"data row7 col13\" >0.885</td>\n",
       "      <td id=\"T_7959a_row7_col14\" class=\"data row7 col14\" >-0.077</td>\n",
       "      <td id=\"T_7959a_row7_col15\" class=\"data row7 col15\" >0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row8\" class=\"row_heading level0 row8\" >ROA</th>\n",
       "      <td id=\"T_7959a_row8_col0\" class=\"data row8 col0\" >0.233</td>\n",
       "      <td id=\"T_7959a_row8_col1\" class=\"data row8 col1\" >0.233</td>\n",
       "      <td id=\"T_7959a_row8_col2\" class=\"data row8 col2\" >0.176</td>\n",
       "      <td id=\"T_7959a_row8_col3\" class=\"data row8 col3\" >0.392</td>\n",
       "      <td id=\"T_7959a_row8_col4\" class=\"data row8 col4\" >0.055</td>\n",
       "      <td id=\"T_7959a_row8_col5\" class=\"data row8 col5\" >0.244</td>\n",
       "      <td id=\"T_7959a_row8_col6\" class=\"data row8 col6\" >0.900</td>\n",
       "      <td id=\"T_7959a_row8_col7\" class=\"data row8 col7\" >0.545</td>\n",
       "      <td id=\"T_7959a_row8_col8\" class=\"data row8 col8\" >1.000</td>\n",
       "      <td id=\"T_7959a_row8_col9\" class=\"data row8 col9\" >0.823</td>\n",
       "      <td id=\"T_7959a_row8_col10\" class=\"data row8 col10\" >-0.148</td>\n",
       "      <td id=\"T_7959a_row8_col11\" class=\"data row8 col11\" >0.462</td>\n",
       "      <td id=\"T_7959a_row8_col12\" class=\"data row8 col12\" >0.433</td>\n",
       "      <td id=\"T_7959a_row8_col13\" class=\"data row8 col13\" >0.478</td>\n",
       "      <td id=\"T_7959a_row8_col14\" class=\"data row8 col14\" >-0.092</td>\n",
       "      <td id=\"T_7959a_row8_col15\" class=\"data row8 col15\" >0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row9\" class=\"row_heading level0 row9\" >ROE2Networth</th>\n",
       "      <td id=\"T_7959a_row9_col0\" class=\"data row9 col0\" >0.184</td>\n",
       "      <td id=\"T_7959a_row9_col1\" class=\"data row9 col1\" >0.184</td>\n",
       "      <td id=\"T_7959a_row9_col2\" class=\"data row9 col2\" >0.120</td>\n",
       "      <td id=\"T_7959a_row9_col3\" class=\"data row9 col3\" >0.435</td>\n",
       "      <td id=\"T_7959a_row9_col4\" class=\"data row9 col4\" >0.049</td>\n",
       "      <td id=\"T_7959a_row9_col5\" class=\"data row9 col5\" >0.193</td>\n",
       "      <td id=\"T_7959a_row9_col6\" class=\"data row9 col6\" >0.874</td>\n",
       "      <td id=\"T_7959a_row9_col7\" class=\"data row9 col7\" >0.395</td>\n",
       "      <td id=\"T_7959a_row9_col8\" class=\"data row9 col8\" >0.823</td>\n",
       "      <td id=\"T_7959a_row9_col9\" class=\"data row9 col9\" >1.000</td>\n",
       "      <td id=\"T_7959a_row9_col10\" class=\"data row9 col10\" >-0.095</td>\n",
       "      <td id=\"T_7959a_row9_col11\" class=\"data row9 col11\" >0.315</td>\n",
       "      <td id=\"T_7959a_row9_col12\" class=\"data row9 col12\" >0.654</td>\n",
       "      <td id=\"T_7959a_row9_col13\" class=\"data row9 col13\" >0.324</td>\n",
       "      <td id=\"T_7959a_row9_col14\" class=\"data row9 col14\" >-0.082</td>\n",
       "      <td id=\"T_7959a_row9_col15\" class=\"data row9 col15\" >0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row10\" class=\"row_heading level0 row10\" >EntValue</th>\n",
       "      <td id=\"T_7959a_row10_col0\" class=\"data row10 col0\" >-0.066</td>\n",
       "      <td id=\"T_7959a_row10_col1\" class=\"data row10 col1\" >-0.066</td>\n",
       "      <td id=\"T_7959a_row10_col2\" class=\"data row10 col2\" >-0.086</td>\n",
       "      <td id=\"T_7959a_row10_col3\" class=\"data row10 col3\" >-0.076</td>\n",
       "      <td id=\"T_7959a_row10_col4\" class=\"data row10 col4\" >-0.095</td>\n",
       "      <td id=\"T_7959a_row10_col5\" class=\"data row10 col5\" >-0.063</td>\n",
       "      <td id=\"T_7959a_row10_col6\" class=\"data row10 col6\" >-0.135</td>\n",
       "      <td id=\"T_7959a_row10_col7\" class=\"data row10 col7\" >-0.018</td>\n",
       "      <td id=\"T_7959a_row10_col8\" class=\"data row10 col8\" >-0.148</td>\n",
       "      <td id=\"T_7959a_row10_col9\" class=\"data row10 col9\" >-0.095</td>\n",
       "      <td id=\"T_7959a_row10_col10\" class=\"data row10 col10\" >1.000</td>\n",
       "      <td id=\"T_7959a_row10_col11\" class=\"data row10 col11\" >-0.002</td>\n",
       "      <td id=\"T_7959a_row10_col12\" class=\"data row10 col12\" >-0.059</td>\n",
       "      <td id=\"T_7959a_row10_col13\" class=\"data row10 col13\" >-0.030</td>\n",
       "      <td id=\"T_7959a_row10_col14\" class=\"data row10 col14\" >0.047</td>\n",
       "      <td id=\"T_7959a_row10_col15\" class=\"data row10 col15\" >-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row11\" class=\"row_heading level0 row11\" >EntValuePerNetSales</th>\n",
       "      <td id=\"T_7959a_row11_col0\" class=\"data row11 col0\" >-0.075</td>\n",
       "      <td id=\"T_7959a_row11_col1\" class=\"data row11 col1\" >-0.074</td>\n",
       "      <td id=\"T_7959a_row11_col2\" class=\"data row11 col2\" >-0.081</td>\n",
       "      <td id=\"T_7959a_row11_col3\" class=\"data row11 col3\" >-0.019</td>\n",
       "      <td id=\"T_7959a_row11_col4\" class=\"data row11 col4\" >-0.128</td>\n",
       "      <td id=\"T_7959a_row11_col5\" class=\"data row11 col5\" >-0.074</td>\n",
       "      <td id=\"T_7959a_row11_col6\" class=\"data row11 col6\" >0.277</td>\n",
       "      <td id=\"T_7959a_row11_col7\" class=\"data row11 col7\" >0.883</td>\n",
       "      <td id=\"T_7959a_row11_col8\" class=\"data row11 col8\" >0.462</td>\n",
       "      <td id=\"T_7959a_row11_col9\" class=\"data row11 col9\" >0.315</td>\n",
       "      <td id=\"T_7959a_row11_col10\" class=\"data row11 col10\" >-0.002</td>\n",
       "      <td id=\"T_7959a_row11_col11\" class=\"data row11 col11\" >1.000</td>\n",
       "      <td id=\"T_7959a_row11_col12\" class=\"data row11 col12\" >0.169</td>\n",
       "      <td id=\"T_7959a_row11_col13\" class=\"data row11 col13\" >0.999</td>\n",
       "      <td id=\"T_7959a_row11_col14\" class=\"data row11 col14\" >-0.076</td>\n",
       "      <td id=\"T_7959a_row11_col15\" class=\"data row11 col15\" >0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row12\" class=\"row_heading level0 row12\" >Price2Book</th>\n",
       "      <td id=\"T_7959a_row12_col0\" class=\"data row12 col0\" >0.137</td>\n",
       "      <td id=\"T_7959a_row12_col1\" class=\"data row12 col1\" >0.137</td>\n",
       "      <td id=\"T_7959a_row12_col2\" class=\"data row12 col2\" >0.101</td>\n",
       "      <td id=\"T_7959a_row12_col3\" class=\"data row12 col3\" >0.501</td>\n",
       "      <td id=\"T_7959a_row12_col4\" class=\"data row12 col4\" >0.038</td>\n",
       "      <td id=\"T_7959a_row12_col5\" class=\"data row12 col5\" >0.144</td>\n",
       "      <td id=\"T_7959a_row12_col6\" class=\"data row12 col6\" >0.614</td>\n",
       "      <td id=\"T_7959a_row12_col7\" class=\"data row12 col7\" >0.058</td>\n",
       "      <td id=\"T_7959a_row12_col8\" class=\"data row12 col8\" >0.433</td>\n",
       "      <td id=\"T_7959a_row12_col9\" class=\"data row12 col9\" >0.654</td>\n",
       "      <td id=\"T_7959a_row12_col10\" class=\"data row12 col10\" >-0.059</td>\n",
       "      <td id=\"T_7959a_row12_col11\" class=\"data row12 col11\" >0.169</td>\n",
       "      <td id=\"T_7959a_row12_col12\" class=\"data row12 col12\" >1.000</td>\n",
       "      <td id=\"T_7959a_row12_col13\" class=\"data row12 col13\" >0.173</td>\n",
       "      <td id=\"T_7959a_row12_col14\" class=\"data row12 col14\" >-0.094</td>\n",
       "      <td id=\"T_7959a_row12_col15\" class=\"data row12 col15\" >-0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row13\" class=\"row_heading level0 row13\" >Price2Sales</th>\n",
       "      <td id=\"T_7959a_row13_col0\" class=\"data row13 col0\" >-0.070</td>\n",
       "      <td id=\"T_7959a_row13_col1\" class=\"data row13 col1\" >-0.070</td>\n",
       "      <td id=\"T_7959a_row13_col2\" class=\"data row13 col2\" >-0.076</td>\n",
       "      <td id=\"T_7959a_row13_col3\" class=\"data row13 col3\" >-0.010</td>\n",
       "      <td id=\"T_7959a_row13_col4\" class=\"data row13 col4\" >-0.120</td>\n",
       "      <td id=\"T_7959a_row13_col5\" class=\"data row13 col5\" >-0.069</td>\n",
       "      <td id=\"T_7959a_row13_col6\" class=\"data row13 col6\" >0.294</td>\n",
       "      <td id=\"T_7959a_row13_col7\" class=\"data row13 col7\" >0.885</td>\n",
       "      <td id=\"T_7959a_row13_col8\" class=\"data row13 col8\" >0.478</td>\n",
       "      <td id=\"T_7959a_row13_col9\" class=\"data row13 col9\" >0.324</td>\n",
       "      <td id=\"T_7959a_row13_col10\" class=\"data row13 col10\" >-0.030</td>\n",
       "      <td id=\"T_7959a_row13_col11\" class=\"data row13 col11\" >0.999</td>\n",
       "      <td id=\"T_7959a_row13_col12\" class=\"data row13 col12\" >0.173</td>\n",
       "      <td id=\"T_7959a_row13_col13\" class=\"data row13 col13\" >1.000</td>\n",
       "      <td id=\"T_7959a_row13_col14\" class=\"data row13 col14\" >-0.080</td>\n",
       "      <td id=\"T_7959a_row13_col15\" class=\"data row13 col15\" >0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row14\" class=\"row_heading level0 row14\" >RetentionRatios</th>\n",
       "      <td id=\"T_7959a_row14_col0\" class=\"data row14 col0\" >0.022</td>\n",
       "      <td id=\"T_7959a_row14_col1\" class=\"data row14 col1\" >0.022</td>\n",
       "      <td id=\"T_7959a_row14_col2\" class=\"data row14 col2\" >0.026</td>\n",
       "      <td id=\"T_7959a_row14_col3\" class=\"data row14 col3\" >-0.091</td>\n",
       "      <td id=\"T_7959a_row14_col4\" class=\"data row14 col4\" >0.023</td>\n",
       "      <td id=\"T_7959a_row14_col5\" class=\"data row14 col5\" >0.027</td>\n",
       "      <td id=\"T_7959a_row14_col6\" class=\"data row14 col6\" >-0.121</td>\n",
       "      <td id=\"T_7959a_row14_col7\" class=\"data row14 col7\" >-0.077</td>\n",
       "      <td id=\"T_7959a_row14_col8\" class=\"data row14 col8\" >-0.092</td>\n",
       "      <td id=\"T_7959a_row14_col9\" class=\"data row14 col9\" >-0.082</td>\n",
       "      <td id=\"T_7959a_row14_col10\" class=\"data row14 col10\" >0.047</td>\n",
       "      <td id=\"T_7959a_row14_col11\" class=\"data row14 col11\" >-0.076</td>\n",
       "      <td id=\"T_7959a_row14_col12\" class=\"data row14 col12\" >-0.094</td>\n",
       "      <td id=\"T_7959a_row14_col13\" class=\"data row14 col13\" >-0.080</td>\n",
       "      <td id=\"T_7959a_row14_col14\" class=\"data row14 col14\" >1.000</td>\n",
       "      <td id=\"T_7959a_row14_col15\" class=\"data row14 col15\" >0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7959a_level0_row15\" class=\"row_heading level0 row15\" >EarningYield</th>\n",
       "      <td id=\"T_7959a_row15_col0\" class=\"data row15 col0\" >0.068</td>\n",
       "      <td id=\"T_7959a_row15_col1\" class=\"data row15 col1\" >0.068</td>\n",
       "      <td id=\"T_7959a_row15_col2\" class=\"data row15 col2\" >0.039</td>\n",
       "      <td id=\"T_7959a_row15_col3\" class=\"data row15 col3\" >0.009</td>\n",
       "      <td id=\"T_7959a_row15_col4\" class=\"data row15 col4\" >0.097</td>\n",
       "      <td id=\"T_7959a_row15_col5\" class=\"data row15 col5\" >0.075</td>\n",
       "      <td id=\"T_7959a_row15_col6\" class=\"data row15 col6\" >0.048</td>\n",
       "      <td id=\"T_7959a_row15_col7\" class=\"data row15 col7\" >0.090</td>\n",
       "      <td id=\"T_7959a_row15_col8\" class=\"data row15 col8\" >0.148</td>\n",
       "      <td id=\"T_7959a_row15_col9\" class=\"data row15 col9\" >0.145</td>\n",
       "      <td id=\"T_7959a_row15_col10\" class=\"data row15 col10\" >-0.011</td>\n",
       "      <td id=\"T_7959a_row15_col11\" class=\"data row15 col11\" >0.007</td>\n",
       "      <td id=\"T_7959a_row15_col12\" class=\"data row15 col12\" >-0.259</td>\n",
       "      <td id=\"T_7959a_row15_col13\" class=\"data row15 col13\" >0.008</td>\n",
       "      <td id=\"T_7959a_row15_col14\" class=\"data row15 col14\" >0.089</td>\n",
       "      <td id=\"T_7959a_row15_col15\" class=\"data row15 col15\" >1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b49516adc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamentals.corr().style.background_gradient(cmap='coolwarm').set_precision(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df0cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals = fundamentals[['stocks','dates','NPS','ROCE','NPMargin','EntValue','Price2Book','RetentionRatios','EarningYield']]\n",
    "\n",
    "fundamentals = fundamentals.sort_values(by=['stocks','dates']).reset_index(drop=True)\n",
    "\n",
    "#fundamentals['NPS_Prcnt_change'] = fundamentals.groupby(['stocks']).NPS.pct_change(periods=1).apply(lambda x: x*100)\n",
    "#fundamentals['ROCE_Prcnt_change'] = fundamentals.groupby(['stocks']).ROCE.pct_change(periods=1).apply(lambda x: x*100)\n",
    "#fundamentals['NPMargin_Prcnt_change'] = fundamentals.groupby(['stocks']).NPMargin.pct_change(periods=1).apply(lambda x: x*100)\n",
    "fundamentals['EntValue_Prcnt_change'] = fundamentals.groupby(['stocks']).EntValue.pct_change(periods=1).apply(lambda x: x*100)\n",
    "fundamentals['Price2Book_Prcnt_change'] = fundamentals.groupby(['stocks']).Price2Book.pct_change(periods=1).apply(lambda x: x*100)\n",
    "#fundamentals['RetentionRatios_Prcnt_change'] = fundamentals.groupby(['stocks']).RetentionRatios.pct_change(periods=1).apply(lambda x: x*100)\n",
    "#fundamentals['EarningYield_Prcnt_change'] = fundamentals.groupby(['stocks']).EarningYield.pct_change(periods=1).apply(lambda x: x*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44da71ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NPS</td>\n",
       "      <td>1.528040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROCE</td>\n",
       "      <td>4.123242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NPMargin</td>\n",
       "      <td>1.239180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EntValue</td>\n",
       "      <td>1.176932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Price2Book</td>\n",
       "      <td>2.726149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RetentionRatios</td>\n",
       "      <td>1.372575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EarningYield</td>\n",
       "      <td>1.888066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature       VIF\n",
       "0              NPS  1.528040\n",
       "1             ROCE  4.123242\n",
       "2         NPMargin  1.239180\n",
       "3         EntValue  1.176932\n",
       "4       Price2Book  2.726149\n",
       "5  RetentionRatios  1.372575\n",
       "6     EarningYield  1.888066"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamentals = fundamentals.sort_values(by=['stocks','dates'],ascending=False).reset_index(drop=True)\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "X = fundamentals[['NPS','ROCE','NPMargin','EntValue','Price2Book','RetentionRatios','EarningYield']]\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "\n",
    "\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93df45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label(df):\n",
    "    \"\"\"\n",
    "    Creates classes of:\n",
    "    - buy(1)\n",
    "    - sell(0)\n",
    "    \n",
    "    Threshold can be changed to fit whatever price change is desired\n",
    "    \"\"\"\n",
    "    result = score(df)\n",
    "    \n",
    "    if result >= 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def score(df,thres=12):\n",
    "    result = 0\n",
    "    if df['NPS'] >= thres :\n",
    "        result += 1\n",
    "    if df['ROCE'] >= thres :\n",
    "        result += 1\n",
    "    if df['NPMargin'] >= thres :\n",
    "        result += 1\n",
    "    if df['EntValue_Prcnt_change'] >= thres :\n",
    "        result += 1\n",
    "    if df['Price2Book_Prcnt_change'] >= thres :\n",
    "        result += 1\n",
    "    if df['RetentionRatios'] >= thres :\n",
    "        result += 1\n",
    "    if df['EarningYield'] >= thres :\n",
    "        result += 1\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c46dc0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6777b67c4234a568cf07bf2621a89c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fundamentals['Label'] = 0.0\n",
    "fundamentals['Score'] = 0.0\n",
    "\n",
    "for stock in tqdm(stocks):\n",
    "    # Assigning the the new DF\n",
    "    new_df = fundamentals[fundamentals['stocks'] == stock]\n",
    "    \n",
    "    new_df['Label'] = new_df.apply(label, axis=1)#.shift(-1)\n",
    "    new_df['Score'] = new_df.apply(score, axis=1)#.shift(-1)\n",
    "    \n",
    "    fundamentals.loc[new_df.index, :] = new_df[:]\n",
    "\n",
    "fundamentals = fundamentals.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c581d729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stocks</th>\n",
       "      <th>dates</th>\n",
       "      <th>NPS</th>\n",
       "      <th>ROCE</th>\n",
       "      <th>NPMargin</th>\n",
       "      <th>EntValue</th>\n",
       "      <th>Price2Book</th>\n",
       "      <th>RetentionRatios</th>\n",
       "      <th>EarningYield</th>\n",
       "      <th>EntValue_Prcnt_change</th>\n",
       "      <th>Price2Book_Prcnt_change</th>\n",
       "      <th>Label</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>22.87</td>\n",
       "      <td>1.64</td>\n",
       "      <td>7.69</td>\n",
       "      <td>4210541.48</td>\n",
       "      <td>1.41</td>\n",
       "      <td>82.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>18.097458</td>\n",
       "      <td>67.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>16.23</td>\n",
       "      <td>1.79</td>\n",
       "      <td>5.63</td>\n",
       "      <td>3565310.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.134007</td>\n",
       "      <td>-35.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>3423771.88</td>\n",
       "      <td>1.30</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.992470</td>\n",
       "      <td>13.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>-7.34</td>\n",
       "      <td>1.81</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>3141292.12</td>\n",
       "      <td>1.15</td>\n",
       "      <td>100.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>27.293663</td>\n",
       "      <td>-22.818792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>13.15</td>\n",
       "      <td>1.99</td>\n",
       "      <td>5.97</td>\n",
       "      <td>2467752.16</td>\n",
       "      <td>1.49</td>\n",
       "      <td>79.88</td>\n",
       "      <td>0.04</td>\n",
       "      <td>18.912431</td>\n",
       "      <td>41.904762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>12.82</td>\n",
       "      <td>1.96</td>\n",
       "      <td>6.06</td>\n",
       "      <td>2075268.45</td>\n",
       "      <td>1.05</td>\n",
       "      <td>79.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>11.250902</td>\n",
       "      <td>-32.258065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>17.55</td>\n",
       "      <td>2.06</td>\n",
       "      <td>8.59</td>\n",
       "      <td>1865394.71</td>\n",
       "      <td>1.55</td>\n",
       "      <td>79.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-36.220041</td>\n",
       "      <td>-87.200661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>14.59</td>\n",
       "      <td>1.89</td>\n",
       "      <td>7.98</td>\n",
       "      <td>2924734.90</td>\n",
       "      <td>12.11</td>\n",
       "      <td>79.43</td>\n",
       "      <td>0.01</td>\n",
       "      <td>102.001890</td>\n",
       "      <td>746.853147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>SBI</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>206.20</td>\n",
       "      <td>2.11</td>\n",
       "      <td>11.78</td>\n",
       "      <td>1447875.02</td>\n",
       "      <td>1.43</td>\n",
       "      <td>79.87</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15.170225</td>\n",
       "      <td>-14.371257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stocks      dates     NPS  ROCE  NPMargin    EntValue  Price2Book  \\\n",
       "120    SBI 2021-03-01   22.87  1.64      7.69  4210541.48        1.41   \n",
       "121    SBI 2020-03-01   16.23  1.79      5.63  3565310.84        0.84   \n",
       "122    SBI 2019-03-01    0.97  0.00      0.35  3423771.88        1.30   \n",
       "123    SBI 2018-03-01   -7.34  1.81     -2.96  3141292.12        1.15   \n",
       "124    SBI 2017-03-01   13.15  1.99      5.97  2467752.16        1.49   \n",
       "125    SBI 2016-03-01   12.82  1.96      6.06  2075268.45        1.05   \n",
       "126    SBI 2015-03-01   17.55  2.06      8.59  1865394.71        1.55   \n",
       "127    SBI 2014-03-01   14.59  1.89      7.98  2924734.90       12.11   \n",
       "128    SBI 2013-03-01  206.20  2.11     11.78  1447875.02        1.43   \n",
       "\n",
       "     RetentionRatios  EarningYield  EntValue_Prcnt_change  \\\n",
       "120            82.50          0.06              18.097458   \n",
       "121           100.00          0.08               4.134007   \n",
       "122           100.00          0.00               8.992470   \n",
       "123           100.00         -0.03              27.293663   \n",
       "124            79.88          0.04              18.912431   \n",
       "125            79.71          0.07              11.250902   \n",
       "126            79.78          0.07             -36.220041   \n",
       "127            79.43          0.01             102.001890   \n",
       "128            79.87          0.10              15.170225   \n",
       "\n",
       "     Price2Book_Prcnt_change  Label  Score  \n",
       "120                67.857143    1.0    4.0  \n",
       "121               -35.384615    0.0    2.0  \n",
       "122                13.043478    0.0    2.0  \n",
       "123               -22.818792    0.0    2.0  \n",
       "124                41.904762    1.0    4.0  \n",
       "125               -32.258065    0.0    2.0  \n",
       "126               -87.200661    0.0    2.0  \n",
       "127               746.853147    1.0    4.0  \n",
       "128               -14.371257    0.0    3.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamentals[fundamentals['stocks'] == 'SBI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a2d164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_28aa6_row0_col0, #T_28aa6_row1_col1, #T_28aa6_row2_col2, #T_28aa6_row3_col3, #T_28aa6_row4_col4, #T_28aa6_row5_col5, #T_28aa6_row6_col6, #T_28aa6_row7_col7, #T_28aa6_row8_col8, #T_28aa6_row9_col9, #T_28aa6_row10_col10 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row0_col1 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row0_col2, #T_28aa6_row2_col0, #T_28aa6_row2_col5 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row0_col3, #T_28aa6_row8_col2 {\n",
       "  background-color: #4b64d5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row0_col4 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row0_col5, #T_28aa6_row4_col2, #T_28aa6_row6_col0 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row0_col6, #T_28aa6_row2_col4 {\n",
       "  background-color: #8fb1fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row0_col7, #T_28aa6_row1_col7, #T_28aa6_row3_col7 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row0_col8, #T_28aa6_row2_col7 {\n",
       "  background-color: #6180e9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row0_col9 {\n",
       "  background-color: #89acfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row0_col10, #T_28aa6_row5_col6 {\n",
       "  background-color: #98b9ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row1_col0, #T_28aa6_row7_col9 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row1_col2, #T_28aa6_row10_col8 {\n",
       "  background-color: #c3d5f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row1_col3, #T_28aa6_row1_col5, #T_28aa6_row2_col9, #T_28aa6_row3_col0, #T_28aa6_row3_col1, #T_28aa6_row3_col10, #T_28aa6_row4_col6, #T_28aa6_row6_col4, #T_28aa6_row6_col7, #T_28aa6_row6_col8, #T_28aa6_row6_col9, #T_28aa6_row7_col2 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row1_col4 {\n",
       "  background-color: #f7b194;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row1_col6 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row1_col8, #T_28aa6_row2_col8, #T_28aa6_row3_col5 {\n",
       "  background-color: #6a8bef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row1_col9 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row1_col10 {\n",
       "  background-color: #ccd9ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row2_col1 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row2_col3 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row2_col6, #T_28aa6_row4_col8, #T_28aa6_row9_col0 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row2_col10, #T_28aa6_row5_col1 {\n",
       "  background-color: #4358cb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row3_col2 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row3_col4 {\n",
       "  background-color: #6c8ff1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row3_col6, #T_28aa6_row4_col9 {\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row3_col8 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row3_col9 {\n",
       "  background-color: #3f53c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row4_col0, #T_28aa6_row9_col6 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row4_col1 {\n",
       "  background-color: #f7bca1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row4_col3, #T_28aa6_row9_col2 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row4_col5, #T_28aa6_row7_col6 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row4_col7, #T_28aa6_row8_col4 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row4_col10 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row5_col0, #T_28aa6_row5_col10, #T_28aa6_row6_col10 {\n",
       "  background-color: #5a78e4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row5_col2 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row5_col3, #T_28aa6_row5_col7 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row5_col4, #T_28aa6_row5_col8 {\n",
       "  background-color: #688aef;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row5_col9 {\n",
       "  background-color: #536edd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row6_col1 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row6_col2, #T_28aa6_row9_col5 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row6_col3, #T_28aa6_row8_col1 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row6_col5 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row7_col0 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row7_col1, #T_28aa6_row9_col3 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row7_col3 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row7_col4 {\n",
       "  background-color: #aec9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row7_col5 {\n",
       "  background-color: #5572df;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row7_col8 {\n",
       "  background-color: #f59c7d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row7_col10 {\n",
       "  background-color: #cbd8ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row8_col0 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row8_col3 {\n",
       "  background-color: #96b7ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row8_col5 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row8_col6 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row8_col7 {\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row8_col9 {\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row8_col10 {\n",
       "  background-color: #9dbdff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row9_col1 {\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row9_col4 {\n",
       "  background-color: #b2ccfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row9_col7 {\n",
       "  background-color: #c7d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row9_col8 {\n",
       "  background-color: #adc9fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row9_col10, #T_28aa6_row10_col9 {\n",
       "  background-color: #e97a5f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row10_col0 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row10_col1 {\n",
       "  background-color: #dfdbd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row10_col2 {\n",
       "  background-color: #5673e0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row10_col3 {\n",
       "  background-color: #5f7fe8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row10_col4 {\n",
       "  background-color: #c5d6f2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row10_col5 {\n",
       "  background-color: #7699f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28aa6_row10_col6 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28aa6_row10_col7 {\n",
       "  background-color: #e7d7ce;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_28aa6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_28aa6_level0_col0\" class=\"col_heading level0 col0\" >NPS</th>\n",
       "      <th id=\"T_28aa6_level0_col1\" class=\"col_heading level0 col1\" >ROCE</th>\n",
       "      <th id=\"T_28aa6_level0_col2\" class=\"col_heading level0 col2\" >NPMargin</th>\n",
       "      <th id=\"T_28aa6_level0_col3\" class=\"col_heading level0 col3\" >EntValue</th>\n",
       "      <th id=\"T_28aa6_level0_col4\" class=\"col_heading level0 col4\" >Price2Book</th>\n",
       "      <th id=\"T_28aa6_level0_col5\" class=\"col_heading level0 col5\" >RetentionRatios</th>\n",
       "      <th id=\"T_28aa6_level0_col6\" class=\"col_heading level0 col6\" >EarningYield</th>\n",
       "      <th id=\"T_28aa6_level0_col7\" class=\"col_heading level0 col7\" >EntValue_Prcnt_change</th>\n",
       "      <th id=\"T_28aa6_level0_col8\" class=\"col_heading level0 col8\" >Price2Book_Prcnt_change</th>\n",
       "      <th id=\"T_28aa6_level0_col9\" class=\"col_heading level0 col9\" >Label</th>\n",
       "      <th id=\"T_28aa6_level0_col10\" class=\"col_heading level0 col10\" >Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row0\" class=\"row_heading level0 row0\" >NPS</th>\n",
       "      <td id=\"T_28aa6_row0_col0\" class=\"data row0 col0\" >1.000</td>\n",
       "      <td id=\"T_28aa6_row0_col1\" class=\"data row0 col1\" >0.240</td>\n",
       "      <td id=\"T_28aa6_row0_col2\" class=\"data row0 col2\" >-0.045</td>\n",
       "      <td id=\"T_28aa6_row0_col3\" class=\"data row0 col3\" >-0.083</td>\n",
       "      <td id=\"T_28aa6_row0_col4\" class=\"data row0 col4\" >0.139</td>\n",
       "      <td id=\"T_28aa6_row0_col5\" class=\"data row0 col5\" >0.027</td>\n",
       "      <td id=\"T_28aa6_row0_col6\" class=\"data row0 col6\" >0.055</td>\n",
       "      <td id=\"T_28aa6_row0_col7\" class=\"data row0 col7\" >0.006</td>\n",
       "      <td id=\"T_28aa6_row0_col8\" class=\"data row0 col8\" >-0.059</td>\n",
       "      <td id=\"T_28aa6_row0_col9\" class=\"data row0 col9\" >0.230</td>\n",
       "      <td id=\"T_28aa6_row0_col10\" class=\"data row0 col10\" >0.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row1\" class=\"row_heading level0 row1\" >ROCE</th>\n",
       "      <td id=\"T_28aa6_row1_col0\" class=\"data row1 col0\" >0.240</td>\n",
       "      <td id=\"T_28aa6_row1_col1\" class=\"data row1 col1\" >1.000</td>\n",
       "      <td id=\"T_28aa6_row1_col2\" class=\"data row1 col2\" >0.360</td>\n",
       "      <td id=\"T_28aa6_row1_col3\" class=\"data row1 col3\" >-0.151</td>\n",
       "      <td id=\"T_28aa6_row1_col4\" class=\"data row1 col4\" >0.600</td>\n",
       "      <td id=\"T_28aa6_row1_col5\" class=\"data row1 col5\" >-0.116</td>\n",
       "      <td id=\"T_28aa6_row1_col6\" class=\"data row1 col6\" >0.043</td>\n",
       "      <td id=\"T_28aa6_row1_col7\" class=\"data row1 col7\" >0.006</td>\n",
       "      <td id=\"T_28aa6_row1_col8\" class=\"data row1 col8\" >-0.027</td>\n",
       "      <td id=\"T_28aa6_row1_col9\" class=\"data row1 col9\" >0.344</td>\n",
       "      <td id=\"T_28aa6_row1_col10\" class=\"data row1 col10\" >0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row2\" class=\"row_heading level0 row2\" >NPMargin</th>\n",
       "      <td id=\"T_28aa6_row2_col0\" class=\"data row2 col0\" >-0.045</td>\n",
       "      <td id=\"T_28aa6_row2_col1\" class=\"data row2 col1\" >0.360</td>\n",
       "      <td id=\"T_28aa6_row2_col2\" class=\"data row2 col2\" >1.000</td>\n",
       "      <td id=\"T_28aa6_row2_col3\" class=\"data row2 col3\" >-0.021</td>\n",
       "      <td id=\"T_28aa6_row2_col4\" class=\"data row2 col4\" >0.055</td>\n",
       "      <td id=\"T_28aa6_row2_col5\" class=\"data row2 col5\" >-0.074</td>\n",
       "      <td id=\"T_28aa6_row2_col6\" class=\"data row2 col6\" >0.097</td>\n",
       "      <td id=\"T_28aa6_row2_col7\" class=\"data row2 col7\" >-0.085</td>\n",
       "      <td id=\"T_28aa6_row2_col8\" class=\"data row2 col8\" >-0.025</td>\n",
       "      <td id=\"T_28aa6_row2_col9\" class=\"data row2 col9\" >-0.011</td>\n",
       "      <td id=\"T_28aa6_row2_col10\" class=\"data row2 col10\" >0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row3\" class=\"row_heading level0 row3\" >EntValue</th>\n",
       "      <td id=\"T_28aa6_row3_col0\" class=\"data row3 col0\" >-0.083</td>\n",
       "      <td id=\"T_28aa6_row3_col1\" class=\"data row3 col1\" >-0.151</td>\n",
       "      <td id=\"T_28aa6_row3_col2\" class=\"data row3 col2\" >-0.021</td>\n",
       "      <td id=\"T_28aa6_row3_col3\" class=\"data row3 col3\" >1.000</td>\n",
       "      <td id=\"T_28aa6_row3_col4\" class=\"data row3 col4\" >-0.070</td>\n",
       "      <td id=\"T_28aa6_row3_col5\" class=\"data row3 col5\" >0.052</td>\n",
       "      <td id=\"T_28aa6_row3_col6\" class=\"data row3 col6\" >-0.026</td>\n",
       "      <td id=\"T_28aa6_row3_col7\" class=\"data row3 col7\" >0.008</td>\n",
       "      <td id=\"T_28aa6_row3_col8\" class=\"data row3 col8\" >0.168</td>\n",
       "      <td id=\"T_28aa6_row3_col9\" class=\"data row3 col9\" >0.006</td>\n",
       "      <td id=\"T_28aa6_row3_col10\" class=\"data row3 col10\" >-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row4\" class=\"row_heading level0 row4\" >Price2Book</th>\n",
       "      <td id=\"T_28aa6_row4_col0\" class=\"data row4 col0\" >0.139</td>\n",
       "      <td id=\"T_28aa6_row4_col1\" class=\"data row4 col1\" >0.600</td>\n",
       "      <td id=\"T_28aa6_row4_col2\" class=\"data row4 col2\" >0.055</td>\n",
       "      <td id=\"T_28aa6_row4_col3\" class=\"data row4 col3\" >-0.070</td>\n",
       "      <td id=\"T_28aa6_row4_col4\" class=\"data row4 col4\" >1.000</td>\n",
       "      <td id=\"T_28aa6_row4_col5\" class=\"data row4 col5\" >-0.087</td>\n",
       "      <td id=\"T_28aa6_row4_col6\" class=\"data row4 col6\" >-0.272</td>\n",
       "      <td id=\"T_28aa6_row4_col7\" class=\"data row4 col7\" >0.167</td>\n",
       "      <td id=\"T_28aa6_row4_col8\" class=\"data row4 col8\" >0.144</td>\n",
       "      <td id=\"T_28aa6_row4_col9\" class=\"data row4 col9\" >0.184</td>\n",
       "      <td id=\"T_28aa6_row4_col10\" class=\"data row4 col10\" >0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row5\" class=\"row_heading level0 row5\" >RetentionRatios</th>\n",
       "      <td id=\"T_28aa6_row5_col0\" class=\"data row5 col0\" >0.027</td>\n",
       "      <td id=\"T_28aa6_row5_col1\" class=\"data row5 col1\" >-0.116</td>\n",
       "      <td id=\"T_28aa6_row5_col2\" class=\"data row5 col2\" >-0.074</td>\n",
       "      <td id=\"T_28aa6_row5_col3\" class=\"data row5 col3\" >0.052</td>\n",
       "      <td id=\"T_28aa6_row5_col4\" class=\"data row5 col4\" >-0.087</td>\n",
       "      <td id=\"T_28aa6_row5_col5\" class=\"data row5 col5\" >1.000</td>\n",
       "      <td id=\"T_28aa6_row5_col6\" class=\"data row5 col6\" >0.088</td>\n",
       "      <td id=\"T_28aa6_row5_col7\" class=\"data row5 col7\" >-0.017</td>\n",
       "      <td id=\"T_28aa6_row5_col8\" class=\"data row5 col8\" >-0.030</td>\n",
       "      <td id=\"T_28aa6_row5_col9\" class=\"data row5 col9\" >0.068</td>\n",
       "      <td id=\"T_28aa6_row5_col10\" class=\"data row5 col10\" >0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row6\" class=\"row_heading level0 row6\" >EarningYield</th>\n",
       "      <td id=\"T_28aa6_row6_col0\" class=\"data row6 col0\" >0.055</td>\n",
       "      <td id=\"T_28aa6_row6_col1\" class=\"data row6 col1\" >0.043</td>\n",
       "      <td id=\"T_28aa6_row6_col2\" class=\"data row6 col2\" >0.097</td>\n",
       "      <td id=\"T_28aa6_row6_col3\" class=\"data row6 col3\" >-0.026</td>\n",
       "      <td id=\"T_28aa6_row6_col4\" class=\"data row6 col4\" >-0.272</td>\n",
       "      <td id=\"T_28aa6_row6_col5\" class=\"data row6 col5\" >0.088</td>\n",
       "      <td id=\"T_28aa6_row6_col6\" class=\"data row6 col6\" >1.000</td>\n",
       "      <td id=\"T_28aa6_row6_col7\" class=\"data row6 col7\" >-0.238</td>\n",
       "      <td id=\"T_28aa6_row6_col8\" class=\"data row6 col8\" >-0.206</td>\n",
       "      <td id=\"T_28aa6_row6_col9\" class=\"data row6 col9\" >-0.013</td>\n",
       "      <td id=\"T_28aa6_row6_col10\" class=\"data row6 col10\" >0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row7\" class=\"row_heading level0 row7\" >EntValue_Prcnt_change</th>\n",
       "      <td id=\"T_28aa6_row7_col0\" class=\"data row7 col0\" >0.006</td>\n",
       "      <td id=\"T_28aa6_row7_col1\" class=\"data row7 col1\" >0.006</td>\n",
       "      <td id=\"T_28aa6_row7_col2\" class=\"data row7 col2\" >-0.085</td>\n",
       "      <td id=\"T_28aa6_row7_col3\" class=\"data row7 col3\" >0.008</td>\n",
       "      <td id=\"T_28aa6_row7_col4\" class=\"data row7 col4\" >0.167</td>\n",
       "      <td id=\"T_28aa6_row7_col5\" class=\"data row7 col5\" >-0.017</td>\n",
       "      <td id=\"T_28aa6_row7_col6\" class=\"data row7 col6\" >-0.238</td>\n",
       "      <td id=\"T_28aa6_row7_col7\" class=\"data row7 col7\" >1.000</td>\n",
       "      <td id=\"T_28aa6_row7_col8\" class=\"data row7 col8\" >0.693</td>\n",
       "      <td id=\"T_28aa6_row7_col9\" class=\"data row7 col9\" >0.288</td>\n",
       "      <td id=\"T_28aa6_row7_col10\" class=\"data row7 col10\" >0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row8\" class=\"row_heading level0 row8\" >Price2Book_Prcnt_change</th>\n",
       "      <td id=\"T_28aa6_row8_col0\" class=\"data row8 col0\" >-0.059</td>\n",
       "      <td id=\"T_28aa6_row8_col1\" class=\"data row8 col1\" >-0.027</td>\n",
       "      <td id=\"T_28aa6_row8_col2\" class=\"data row8 col2\" >-0.025</td>\n",
       "      <td id=\"T_28aa6_row8_col3\" class=\"data row8 col3\" >0.168</td>\n",
       "      <td id=\"T_28aa6_row8_col4\" class=\"data row8 col4\" >0.144</td>\n",
       "      <td id=\"T_28aa6_row8_col5\" class=\"data row8 col5\" >-0.030</td>\n",
       "      <td id=\"T_28aa6_row8_col6\" class=\"data row8 col6\" >-0.206</td>\n",
       "      <td id=\"T_28aa6_row8_col7\" class=\"data row8 col7\" >0.693</td>\n",
       "      <td id=\"T_28aa6_row8_col8\" class=\"data row8 col8\" >1.000</td>\n",
       "      <td id=\"T_28aa6_row8_col9\" class=\"data row8 col9\" >0.208</td>\n",
       "      <td id=\"T_28aa6_row8_col10\" class=\"data row8 col10\" >0.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row9\" class=\"row_heading level0 row9\" >Label</th>\n",
       "      <td id=\"T_28aa6_row9_col0\" class=\"data row9 col0\" >0.230</td>\n",
       "      <td id=\"T_28aa6_row9_col1\" class=\"data row9 col1\" >0.344</td>\n",
       "      <td id=\"T_28aa6_row9_col2\" class=\"data row9 col2\" >-0.011</td>\n",
       "      <td id=\"T_28aa6_row9_col3\" class=\"data row9 col3\" >0.006</td>\n",
       "      <td id=\"T_28aa6_row9_col4\" class=\"data row9 col4\" >0.184</td>\n",
       "      <td id=\"T_28aa6_row9_col5\" class=\"data row9 col5\" >0.068</td>\n",
       "      <td id=\"T_28aa6_row9_col6\" class=\"data row9 col6\" >-0.013</td>\n",
       "      <td id=\"T_28aa6_row9_col7\" class=\"data row9 col7\" >0.288</td>\n",
       "      <td id=\"T_28aa6_row9_col8\" class=\"data row9 col8\" >0.208</td>\n",
       "      <td id=\"T_28aa6_row9_col9\" class=\"data row9 col9\" >1.000</td>\n",
       "      <td id=\"T_28aa6_row9_col10\" class=\"data row9 col10\" >0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28aa6_level0_row10\" class=\"row_heading level0 row10\" >Score</th>\n",
       "      <td id=\"T_28aa6_row10_col0\" class=\"data row10 col0\" >0.274</td>\n",
       "      <td id=\"T_28aa6_row10_col1\" class=\"data row10 col1\" >0.435</td>\n",
       "      <td id=\"T_28aa6_row10_col2\" class=\"data row10 col2\" >0.017</td>\n",
       "      <td id=\"T_28aa6_row10_col3\" class=\"data row10 col3\" >-0.011</td>\n",
       "      <td id=\"T_28aa6_row10_col4\" class=\"data row10 col4\" >0.255</td>\n",
       "      <td id=\"T_28aa6_row10_col5\" class=\"data row10 col5\" >0.092</td>\n",
       "      <td id=\"T_28aa6_row10_col6\" class=\"data row10 col6\" >0.092</td>\n",
       "      <td id=\"T_28aa6_row10_col7\" class=\"data row10 col7\" >0.430</td>\n",
       "      <td id=\"T_28aa6_row10_col8\" class=\"data row10 col8\" >0.287</td>\n",
       "      <td id=\"T_28aa6_row10_col9\" class=\"data row10 col9\" >0.821</td>\n",
       "      <td id=\"T_28aa6_row10_col10\" class=\"data row10 col10\" >1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b4967814c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fundamentals.corr().style.background_gradient(cmap='coolwarm').set_precision(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "122a5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = fundamentals.drop(columns=['Label','Score','stocks','dates','EntValue'], axis=1)\n",
    "X = X.replace((np.inf, -np.inf, np.nan), 0)\n",
    "y = fundamentals.Label\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit_transform(X)\n",
    "\n",
    "# Train, test, split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=50,shuffle=True,train_size=0.7)\n",
    "\n",
    "pre_optimization_precision = []\n",
    "post_optimization_precision = []\n",
    "pre_optimization_accuracy = []\n",
    "post_optimization_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aac6372f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the model\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Fitting and training\n",
    "AdaBoost_clf = AdaBoostClassifier()\n",
    "AdaBoost_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faeae924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        72\n",
      "\n",
      "    accuracy                           1.00       132\n",
      "   macro avg       1.00      1.00      1.00       132\n",
      "weighted avg       1.00      1.00      1.00       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "AdaBoost_pred = AdaBoost_clf.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "AdaBoost_report = classification_report(y_test, AdaBoost_pred)\n",
    "print(AdaBoost_report)\n",
    "\n",
    "pre_optimization_precision.append(precision_score(y_true=y_test, y_pred=AdaBoost_pred))\n",
    "pre_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=AdaBoost_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af733580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END learning_rate=1, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=1, n_estimators=50;, score=(train=1.000, test=0.965) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=1, n_estimators=50;, score=(train=1.000, test=0.988) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=1, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=1, n_estimators=50;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=1, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=1, n_estimators=100;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=1, n_estimators=100;, score=(train=1.000, test=0.988) total time=   0.1s\n",
      "[CV 4/5] END learning_rate=1, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=1, n_estimators=100;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=1, n_estimators=200;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 2/5] END learning_rate=1, n_estimators=200;, score=(train=1.000, test=0.931) total time=   0.2s\n",
      "[CV 3/5] END learning_rate=1, n_estimators=200;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 4/5] END learning_rate=1, n_estimators=200;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 5/5] END learning_rate=1, n_estimators=200;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/5] END learning_rate=1, n_estimators=500;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 2/5] END learning_rate=1, n_estimators=500;, score=(train=1.000, test=0.930) total time=   0.7s\n",
      "[CV 3/5] END learning_rate=1, n_estimators=500;, score=(train=1.000, test=0.988) total time=   0.7s\n",
      "[CV 4/5] END learning_rate=1, n_estimators=500;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 5/5] END learning_rate=1, n_estimators=500;, score=(train=1.000, test=0.977) total time=   0.7s\n",
      "[CV 1/5] END learning_rate=1, n_estimators=600;, score=(train=1.000, test=1.000) total time=   0.8s\n",
      "[CV 2/5] END learning_rate=1, n_estimators=600;, score=(train=1.000, test=0.930) total time=   0.8s\n",
      "[CV 3/5] END learning_rate=1, n_estimators=600;, score=(train=1.000, test=0.988) total time=   0.8s\n",
      "[CV 4/5] END learning_rate=1, n_estimators=600;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 5/5] END learning_rate=1, n_estimators=600;, score=(train=1.000, test=0.977) total time=   0.7s\n",
      "[CV 1/5] END learning_rate=1, n_estimators=700;, score=(train=1.000, test=1.000) total time=   1.0s\n",
      "[CV 2/5] END learning_rate=1, n_estimators=700;, score=(train=1.000, test=0.930) total time=   1.1s\n",
      "[CV 3/5] END learning_rate=1, n_estimators=700;, score=(train=1.000, test=0.988) total time=   1.1s\n",
      "[CV 4/5] END learning_rate=1, n_estimators=700;, score=(train=1.000, test=1.000) total time=   1.1s\n",
      "[CV 5/5] END learning_rate=1, n_estimators=700;, score=(train=1.000, test=0.977) total time=   1.0s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=50;, score=(train=0.956, test=0.929) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=50;, score=(train=0.965, test=0.918) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=50;, score=(train=0.941, test=0.784) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=50;, score=(train=0.938, test=0.965) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=50;, score=(train=0.980, test=0.892) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=100;, score=(train=0.991, test=0.965) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=100;, score=(train=0.991, test=0.965) total time=   0.1s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=100;, score=(train=0.994, test=0.931) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=100;, score=(train=0.991, test=1.000) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=100;, score=(train=0.988, test=0.904) total time=   0.1s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=200;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=200;, score=(train=1.000, test=0.977) total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=200;, score=(train=1.000, test=0.943) total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=200;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=200;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=500;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=500;, score=(train=1.000, test=0.965) total time=   0.6s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=500;, score=(train=1.000, test=0.988) total time=   0.6s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=500;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=500;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=600;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=600;, score=(train=1.000, test=0.965) total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=600;, score=(train=1.000, test=0.988) total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=600;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=600;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.1, n_estimators=700;, score=(train=1.000, test=1.000) total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.1, n_estimators=700;, score=(train=1.000, test=0.965) total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.1, n_estimators=700;, score=(train=1.000, test=0.988) total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.1, n_estimators=700;, score=(train=1.000, test=1.000) total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.1, n_estimators=700;, score=(train=1.000, test=1.000) total time=   0.8s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=50;, score=(train=0.780, test=0.665) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=50;, score=(train=0.778, test=0.534) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=50;, score=(train=0.788, test=0.500) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=50;, score=(train=0.781, test=0.693) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=50;, score=(train=0.910, test=0.830) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=100;, score=(train=0.923, test=0.880) total time=   0.0s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=100;, score=(train=0.845, test=0.733) total time=   0.0s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=100;, score=(train=0.897, test=0.671) total time=   0.0s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=100;, score=(train=0.905, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=100;, score=(train=0.944, test=0.826) total time=   0.0s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=200;, score=(train=0.932, test=0.892) total time=   0.2s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=200;, score=(train=0.941, test=0.858) total time=   0.2s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=200;, score=(train=0.911, test=0.686) total time=   0.2s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=200;, score=(train=0.926, test=0.965) total time=   0.2s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=200;, score=(train=0.947, test=0.826) total time=   0.2s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=500;, score=(train=0.956, test=0.965) total time=   0.5s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=500;, score=(train=0.968, test=0.942) total time=   0.5s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=500;, score=(train=0.947, test=0.784) total time=   0.5s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=500;, score=(train=0.959, test=0.977) total time=   0.6s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=500;, score=(train=0.977, test=0.879) total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=600;, score=(train=0.959, test=0.965) total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END learning_rate=0.01, n_estimators=600;, score=(train=0.968, test=0.930) total time=   0.7s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=600;, score=(train=0.953, test=0.784) total time=   0.7s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=600;, score=(train=0.974, test=0.988) total time=   0.7s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=600;, score=(train=0.983, test=0.892) total time=   0.7s\n",
      "[CV 1/5] END learning_rate=0.01, n_estimators=700;, score=(train=0.965, test=0.965) total time=   0.8s\n",
      "[CV 2/5] END learning_rate=0.01, n_estimators=700;, score=(train=0.977, test=0.930) total time=   0.8s\n",
      "[CV 3/5] END learning_rate=0.01, n_estimators=700;, score=(train=0.959, test=0.797) total time=   0.8s\n",
      "[CV 4/5] END learning_rate=0.01, n_estimators=700;, score=(train=0.991, test=1.000) total time=   0.8s\n",
      "[CV 5/5] END learning_rate=0.01, n_estimators=700;, score=(train=0.985, test=0.892) total time=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=AdaBoostClassifier(),\n",
       "             param_grid={'learning_rate': [1, 0.1, 0.01],\n",
       "                         'n_estimators': [50, 100, 200, 500, 600, 700]},\n",
       "             return_train_score=True, scoring='f1_macro', verbose=5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters to Tune\n",
    "params = {'n_estimators': [50, 100, 200, 500, 600 , 700],\n",
    "          'learning_rate': [1, .1, .01]}\n",
    "\n",
    "AdaBoost_search = GridSearchCV(AdaBoost_clf, params, cv=5, return_train_score=True, verbose=5, scoring='f1_macro')\n",
    "\n",
    "AdaBoost_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ddce0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.990721 using {'learning_rate': 1, 'n_estimators': 50}\n",
      "Mean Training Score: 0.9718392771651936\n",
      "Mean Testing Score: 1.0\n",
      "\n",
      "Best Parameter Found:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'n_estimators': 50}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best Accuracy: %f using %s\" % (AdaBoost_search.best_score_, AdaBoost_search.best_params_))\n",
    "print(\"Mean Training Score:\", np.mean(AdaBoost_search.cv_results_['mean_train_score']))\n",
    "print(\"Mean Testing Score:\", AdaBoost_search.score(X, y))\n",
    "print(\"\\nBest Parameter Found:\")\n",
    "AdaBoost_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d87120f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdaBoost_search = AdaBoost_search.best_estimator_\n",
    "\n",
    "AdaBoost_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dd0d351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        72\n",
      "\n",
      "    accuracy                           1.00       132\n",
      "   macro avg       1.00      1.00      1.00       132\n",
      "weighted avg       1.00      1.00      1.00       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "AdaBoost_pred = AdaBoost_search.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "AdaBoost_report = classification_report(y_test, AdaBoost_pred)\n",
    "print(AdaBoost_report)\n",
    "\n",
    "post_optimization_precision.append(precision_score(y_true=y_test, y_pred=AdaBoost_pred))\n",
    "post_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=AdaBoost_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9c19819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2b498f0f730>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "AdaBoost_cm = confusion_matrix(y_test, AdaBoost_pred, normalize='all')\n",
    "AdaBoost_cmd = ConfusionMatrixDisplay(AdaBoost_cm)\n",
    "AdaBoost_cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae081837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    AdaBoost_search, X_test, y_test, name=\"AdaBoost\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"AdaBoost - 2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b776e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fitting and training\n",
    "LogReg_clf = LogisticRegression()\n",
    "LogReg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8185481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.70      0.68        60\n",
      "         1.0       0.74      0.71      0.72        72\n",
      "\n",
      "    accuracy                           0.70       132\n",
      "   macro avg       0.70      0.70      0.70       132\n",
      "weighted avg       0.71      0.70      0.71       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "LogReg_pred = LogReg_clf.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "LogReg_report = classification_report(y_test, LogReg_pred)\n",
    "print(LogReg_report)\n",
    "pre_optimization_precision.append(precision_score(y_true=y_test, y_pred=LogReg_pred))\n",
    "pre_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=LogReg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce18d804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.703, test=0.607) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.647, test=0.712) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.674, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.649, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.697, test=0.591) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.625, test=0.679) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.670, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.641, test=0.686) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.755, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.736, test=0.705) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.726, test=0.749) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.785, test=0.580) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.710, test=0.778) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.802, test=0.776) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.633) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.683, test=0.737) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.697, test=0.586) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.667, test=0.733) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.770, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.723, test=0.774) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.725, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.811, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.774) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.741, test=0.727) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.777, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.817, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.736, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.781, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.811, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.781, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.811, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.781, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.703, test=0.607) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.647, test=0.712) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.674, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.649, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.697, test=0.591) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.625, test=0.679) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.670, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.636, test=0.686) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.703, test=0.607) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.647, test=0.712) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.674, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.649, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.697, test=0.591) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.625, test=0.679) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.670, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.636, test=0.686) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.703, test=0.607) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.647, test=0.712) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.674, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.649, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.633, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.697, test=0.591) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.625, test=0.679) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.670, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.636, test=0.686) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.703, test=0.607) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.647, test=0.712) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.674, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.649, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.633, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.697, test=0.591) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.625, test=0.679) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.670, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.636, test=0.686) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.703, test=0.607) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.647, test=0.712) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.674, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.649, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.697, test=0.591) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.625, test=0.679) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.670, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.636, test=0.686) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.703, test=0.607) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.647, test=0.712) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.674, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.649, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.697, test=0.591) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.625, test=0.679) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.670, test=0.517) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.636, test=0.686) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=1.0, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.729, test=0.636) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.730, test=0.749) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.758, test=0.563) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.711, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.797, test=0.776) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.722, test=0.581) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.662, test=0.732) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.611) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.685, test=0.705) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.733, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.724, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.811, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.729, test=0.685) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.727, test=0.749) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.777, test=0.540) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.711, test=0.778) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.810, test=0.772) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.778, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.814, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.723, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.739, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.778, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.800, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.778, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.811, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.776) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.778, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.633, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.778, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.814, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.778, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.778, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.811, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.778, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.642, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.723, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.717, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.744, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.633, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.722, test=0.581) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.658, test=0.732) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.621) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.681, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.723, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.717, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.744, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.722, test=0.581) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.658, test=0.732) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.621) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.681, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.723, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.717, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.744, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.722, test=0.581) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.658, test=0.732) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.621) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.681, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.723, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.717, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.744, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.722, test=0.581) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.658, test=0.732) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.621) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.681, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.723, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.717, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.744, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.722, test=0.581) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.658, test=0.732) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.621) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.681, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.723, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.717, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.744, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.722, test=0.581) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.658, test=0.732) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.621) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.681, test=0.691) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.706) total time=   0.0s\n",
      "[CV 1/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=7.59375, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.723, test=0.726) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.736, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.783, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.724, test=0.748) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.808, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.737, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.752) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.588) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.680, test=0.733) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.751, test=0.717) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.811, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.642, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.726) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.736, test=0.693) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.774, test=0.575) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.724, test=0.759) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.813, test=0.765) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.815, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.739, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.803, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.811, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.776) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.808, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.808, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.730, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.679, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.747) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.751, test=0.686) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.730, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.679, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.747) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.751, test=0.686) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.730, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.679, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.747) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.751, test=0.686) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.730, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.679, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.747) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.751, test=0.686) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.730, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.679, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.747) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.751, test=0.686) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.730, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.679, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.747) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.683, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.751, test=0.686) total time=   0.0s\n",
      "[CV 1/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=57.6650390625, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.736, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.722, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.818, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.738, test=0.621) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.738) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.772, test=0.573) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.713, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.744, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.731, test=0.760) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.815, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.723, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.736, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.724, test=0.748) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.731, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.808, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.723, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.739, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.731, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.803, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.731, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.731, test=0.760) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.808, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.787) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.778, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.720, test=0.763) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.739, test=0.705) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.731, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.811, test=0.754) total time=   0.2s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.776) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.716) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.589) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.760) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.754) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=True, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.734, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l1, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.686, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=liblinear;, score=(train=0.737, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.01, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.734, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l1, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.686, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=liblinear;, score=(train=0.737, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=0.1, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.734, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.686, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=liblinear;, score=(train=0.737, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=1, penalty=l2, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.734, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.686, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=liblinear;, score=(train=0.737, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=10, penalty=l2, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.734, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l1, solver=saga;, score=(train=0.637, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.686, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=liblinear;, score=(train=0.737, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.467, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=50, penalty=l2, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.734, test=0.589) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.683, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.612) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.681, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.691) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l1, solver=saga;, score=(train=0.637, test=0.590) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.572) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.676, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.622) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.686, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=liblinear;, score=(train=0.737, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.527, test=0.553) total time=   0.0s\n",
      "[CV 2/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.461, test=0.437) total time=   0.0s\n",
      "[CV 3/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.520, test=0.461) total time=   0.0s\n",
      "[CV 4/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.507, test=0.497) total time=   0.0s\n",
      "[CV 5/5] END C=437.8938903808594, fit_intercept=False, intercept_scaling=100, penalty=l2, solver=saga;, score=(train=0.633, test=0.599) total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1.0, 7.59375, 57.6650390625, 437.8938903808594],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'intercept_scaling': [0.01, 0.1, 1, 10, 50, 100],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear', 'saga']},\n",
       "             return_train_score=True, scoring='f1_macro', verbose=5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters to Tune\n",
    "params = {'penalty': ['l1', 'l2'],\n",
    "          'C': [1.5**n for n in range(0, 20, 5)],\n",
    "          'fit_intercept': [True, False],\n",
    "          'intercept_scaling': [0.01, 0.1, 1, 10, 50, 100],\n",
    "          'solver': ['liblinear', 'saga']}\n",
    "\n",
    "LogReg_search = GridSearchCV(LogReg_clf, params, cv=5, return_train_score=True, verbose=5, scoring='f1_macro')\n",
    "\n",
    "LogReg_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d2dc259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.721140 using {'C': 1.0, 'fit_intercept': True, 'intercept_scaling': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Mean Training Score: 0.6279057673705756\n",
      "Mean Testing Score: 0.732332025759896\n",
      "\n",
      "Best Parameter Found:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 10,\n",
       " 'penalty': 'l1',\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best Accuracy: %f using %s\" % (LogReg_search.best_score_, LogReg_search.best_params_))\n",
    "print(\"Mean Training Score:\", np.mean(LogReg_search.cv_results_['mean_train_score']))\n",
    "print(\"Mean Testing Score:\", LogReg_search.score(X, y))\n",
    "print(\"\\nBest Parameter Found:\")\n",
    "LogReg_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db38a6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(intercept_scaling=10, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg_search = LogReg_search.best_estimator_\n",
    "\n",
    "LogReg_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b6f5fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.68      0.67        60\n",
      "         1.0       0.73      0.71      0.72        72\n",
      "\n",
      "    accuracy                           0.70       132\n",
      "   macro avg       0.69      0.70      0.70       132\n",
      "weighted avg       0.70      0.70      0.70       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "LogReg_pred = LogReg_search.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "LogReg_report = classification_report(y_test, LogReg_pred)\n",
    "print(LogReg_report)\n",
    "post_optimization_precision.append(precision_score(y_true=y_test, y_pred=LogReg_pred))\n",
    "post_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=LogReg_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a3f8a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2b4991cceb0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "LogReg_cm = confusion_matrix(y_test, LogReg_pred, normalize='all')\n",
    "LogReg_cmd = ConfusionMatrixDisplay(LogReg_cm)\n",
    "LogReg_cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d74105fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    LogReg_search, X_test, y_test, name=\"Logistic Regression\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"Logistic Regression - 2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74435e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Fitting and training\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "076896af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.50      0.63        60\n",
      "         1.0       0.69      0.93      0.79        72\n",
      "\n",
      "    accuracy                           0.73       132\n",
      "   macro avg       0.77      0.72      0.71       132\n",
      "weighted avg       0.77      0.73      0.72       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "svm_pred = svm_clf.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "svm_report = classification_report(y_test, svm_pred)\n",
    "print(svm_report)\n",
    "pre_optimization_precision.append(precision_score(y_true=y_test, y_pred=svm_pred))\n",
    "pre_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7828374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 42 candidates, totalling 210 fits\n",
      "[CV 1/5] END C=0.0001, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.001, kernel=linear;, score=(train=0.773, test=0.729) total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.001, kernel=linear;, score=(train=0.753, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.001, kernel=linear;, score=(train=0.765, test=0.668) total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.001, kernel=linear;, score=(train=0.758, test=0.713) total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.001, kernel=linear;, score=(train=0.804, test=0.793) total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.0001, gamma=0.0001, kernel=linear;, score=(train=0.773, test=0.729) total time=   0.0s\n",
      "[CV 2/5] END C=0.0001, gamma=0.0001, kernel=linear;, score=(train=0.753, test=0.739) total time=   0.0s\n",
      "[CV 3/5] END C=0.0001, gamma=0.0001, kernel=linear;, score=(train=0.765, test=0.668) total time=   0.0s\n",
      "[CV 4/5] END C=0.0001, gamma=0.0001, kernel=linear;, score=(train=0.758, test=0.713) total time=   0.0s\n",
      "[CV 5/5] END C=0.0001, gamma=0.0001, kernel=linear;, score=(train=0.804, test=0.793) total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.001, kernel=linear;, score=(train=0.745, test=0.731) total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.001, kernel=linear;, score=(train=0.756, test=0.727) total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.001, kernel=linear;, score=(train=0.771, test=0.610) total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.001, kernel=linear;, score=(train=0.745, test=0.736) total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.001, kernel=linear;, score=(train=0.816, test=0.779) total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.001, gamma=0.0001, kernel=linear;, score=(train=0.745, test=0.731) total time=   0.0s\n",
      "[CV 2/5] END C=0.001, gamma=0.0001, kernel=linear;, score=(train=0.756, test=0.727) total time=   0.0s\n",
      "[CV 3/5] END C=0.001, gamma=0.0001, kernel=linear;, score=(train=0.771, test=0.610) total time=   0.0s\n",
      "[CV 4/5] END C=0.001, gamma=0.0001, kernel=linear;, score=(train=0.745, test=0.736) total time=   0.0s\n",
      "[CV 5/5] END C=0.001, gamma=0.0001, kernel=linear;, score=(train=0.816, test=0.779) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=(train=0.377, test=0.492) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=(train=0.411, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=(train=0.404, test=0.391) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=(train=0.404, test=0.391) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.001, kernel=sigmoid;, score=(train=0.411, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.001, kernel=linear;, score=(train=0.733, test=0.741) total time=   0.1s\n",
      "[CV 2/5] END C=0.01, gamma=0.001, kernel=linear;, score=(train=0.753, test=0.727) total time=   0.6s\n",
      "[CV 3/5] END C=0.01, gamma=0.001, kernel=linear;, score=(train=0.777, test=0.575) total time=   0.2s\n",
      "[CV 4/5] END C=0.01, gamma=0.001, kernel=linear;, score=(train=0.739, test=0.737) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.001, kernel=linear;, score=(train=0.822, test=0.751) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.0001, kernel=rbf;, score=(train=0.362, test=0.362) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 2/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 3/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 4/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.0001, kernel=sigmoid;, score=(train=0.362, test=0.362) total time=   0.0s\n",
      "[CV 1/5] END C=0.01, gamma=0.0001, kernel=linear;, score=(train=0.733, test=0.741) total time=   0.1s\n",
      "[CV 2/5] END C=0.01, gamma=0.0001, kernel=linear;, score=(train=0.753, test=0.727) total time=   0.6s\n",
      "[CV 3/5] END C=0.01, gamma=0.0001, kernel=linear;, score=(train=0.777, test=0.575) total time=   0.2s\n",
      "[CV 4/5] END C=0.01, gamma=0.0001, kernel=linear;, score=(train=0.739, test=0.737) total time=   0.0s\n",
      "[CV 5/5] END C=0.01, gamma=0.0001, kernel=linear;, score=(train=0.822, test=0.751) total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.629, test=0.517) total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.565, test=0.609) total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.572, test=0.492) total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.636, test=0.544) total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=rbf;, score=(train=0.613, test=0.515) total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=(train=0.411, test=0.529) total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=(train=0.392, test=0.313) total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=(train=0.400, test=0.398) total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=(train=0.425, test=0.441) total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=(train=0.422, test=0.379) total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=linear;, score=(train=0.739, test=0.741) total time=   1.1s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=linear;, score=(train=0.759, test=0.727) total time=  13.3s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=linear;, score=(train=0.777, test=0.575) total time=   1.5s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=linear;, score=(train=0.739, test=0.737) total time=   0.4s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=linear;, score=(train=0.816, test=0.751) total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.767, test=0.675) total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.743, test=0.810) total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.762, test=0.705) total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.801, test=0.747) total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=rbf;, score=(train=0.751, test=0.676) total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=(train=0.700, test=0.705) total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=(train=0.597, test=0.590) total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=(train=0.654, test=0.591) total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=(train=0.583, test=0.618) total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=(train=0.640, test=0.559) total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=(train=0.739, test=0.741) total time=   1.1s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=(train=0.759, test=0.727) total time=  13.3s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=(train=0.777, test=0.575) total time=   1.6s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=(train=0.739, test=0.737) total time=   0.4s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=(train=0.816, test=0.751) total time=   0.0s\n",
      "[CV 1/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.954, test=0.722) total time=   0.0s\n",
      "[CV 2/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.954, test=0.803) total time=   0.0s\n",
      "[CV 3/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.963, test=0.774) total time=   0.0s\n",
      "[CV 4/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.962, test=0.719) total time=   0.0s\n",
      "[CV 5/5] END C=1, gamma=0.001, kernel=rbf;, score=(train=0.954, test=0.730) total time=   0.0s\n",
      "[CV 1/5] END C=1, gamma=0.001, kernel=sigmoid;, score=(train=0.319, test=0.440) total time=   0.0s\n",
      "[CV 2/5] END C=1, gamma=0.001, kernel=sigmoid;, score=(train=0.330, test=0.213) total time=   0.0s\n",
      "[CV 3/5] END C=1, gamma=0.001, kernel=sigmoid;, score=(train=0.312, test=0.248) total time=   0.0s\n",
      "[CV 4/5] END C=1, gamma=0.001, kernel=sigmoid;, score=(train=0.300, test=0.416) total time=   0.0s\n",
      "[CV 5/5] END C=1, gamma=0.001, kernel=sigmoid;, score=(train=0.301, test=0.324) total time=   0.0s\n",
      "[CV 1/5] END C=1, gamma=0.001, kernel=linear;, score=(train=0.745, test=0.763) total time=  18.9s\n",
      "[CV 2/5] END C=1, gamma=0.001, kernel=linear;, score=(train=0.753, test=0.727) total time=  14.6s\n",
      "[CV 3/5] END C=1, gamma=0.001, kernel=linear;, score=(train=0.777, test=0.565) total time=  42.2s\n",
      "[CV 4/5] END C=1, gamma=0.001, kernel=linear;, score=(train=0.739, test=0.737) total time=   3.2s\n",
      "[CV 5/5] END C=1, gamma=0.001, kernel=linear;, score=(train=0.822, test=0.751) total time=   0.5s\n",
      "[CV 1/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.884, test=0.770) total time=   0.0s\n",
      "[CV 2/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.867, test=0.794) total time=   0.0s\n",
      "[CV 3/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.851, test=0.823) total time=   0.0s\n",
      "[CV 4/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.880, test=0.656) total time=   0.0s\n",
      "[CV 5/5] END C=1, gamma=0.0001, kernel=rbf;, score=(train=0.867, test=0.819) total time=   0.0s\n",
      "[CV 1/5] END C=1, gamma=0.0001, kernel=sigmoid;, score=(train=0.622, test=0.537) total time=   0.0s\n",
      "[CV 2/5] END C=1, gamma=0.0001, kernel=sigmoid;, score=(train=0.538, test=0.406) total time=   0.0s\n",
      "[CV 3/5] END C=1, gamma=0.0001, kernel=sigmoid;, score=(train=0.579, test=0.570) total time=   0.0s\n",
      "[CV 4/5] END C=1, gamma=0.0001, kernel=sigmoid;, score=(train=0.532, test=0.666) total time=   0.0s\n",
      "[CV 5/5] END C=1, gamma=0.0001, kernel=sigmoid;, score=(train=0.618, test=0.641) total time=   0.0s\n",
      "[CV 1/5] END C=1, gamma=0.0001, kernel=linear;, score=(train=0.745, test=0.763) total time=  17.9s\n",
      "[CV 2/5] END C=1, gamma=0.0001, kernel=linear;, score=(train=0.753, test=0.727) total time=  12.8s\n",
      "[CV 3/5] END C=1, gamma=0.0001, kernel=linear;, score=(train=0.777, test=0.565) total time=  45.0s\n",
      "[CV 4/5] END C=1, gamma=0.0001, kernel=linear;, score=(train=0.739, test=0.737) total time=   3.3s\n",
      "[CV 5/5] END C=1, gamma=0.0001, kernel=linear;, score=(train=0.822, test=0.751) total time=   0.5s\n",
      "[CV 1/5] END C=2, gamma=0.001, kernel=rbf;, score=(train=0.957, test=0.748) total time=   0.0s\n",
      "[CV 2/5] END C=2, gamma=0.001, kernel=rbf;, score=(train=0.968, test=0.801) total time=   0.0s\n",
      "[CV 3/5] END C=2, gamma=0.001, kernel=rbf;, score=(train=0.974, test=0.774) total time=   0.0s\n",
      "[CV 4/5] END C=2, gamma=0.001, kernel=rbf;, score=(train=0.971, test=0.736) total time=   0.0s\n",
      "[CV 5/5] END C=2, gamma=0.001, kernel=rbf;, score=(train=0.980, test=0.705) total time=   0.0s\n",
      "[CV 1/5] END C=2, gamma=0.001, kernel=sigmoid;, score=(train=0.329, test=0.464) total time=   0.0s\n",
      "[CV 2/5] END C=2, gamma=0.001, kernel=sigmoid;, score=(train=0.327, test=0.213) total time=   0.0s\n",
      "[CV 3/5] END C=2, gamma=0.001, kernel=sigmoid;, score=(train=0.313, test=0.248) total time=   0.0s\n",
      "[CV 4/5] END C=2, gamma=0.001, kernel=sigmoid;, score=(train=0.295, test=0.416) total time=   0.0s\n",
      "[CV 5/5] END C=2, gamma=0.001, kernel=sigmoid;, score=(train=0.301, test=0.324) total time=   0.0s\n",
      "[CV 1/5] END C=2, gamma=0.001, kernel=linear;, score=(train=0.745, test=0.752) total time=   7.3s\n",
      "[CV 2/5] END C=2, gamma=0.001, kernel=linear;, score=(train=0.747, test=0.727) total time=   6.7s\n",
      "[CV 3/5] END C=2, gamma=0.001, kernel=linear;, score=(train=0.777, test=0.565) total time=  28.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2, gamma=0.001, kernel=linear;, score=(train=0.742, test=0.737) total time=  17.3s\n",
      "[CV 5/5] END C=2, gamma=0.001, kernel=linear;, score=(train=0.824, test=0.751) total time=   1.6s\n",
      "[CV 1/5] END C=2, gamma=0.0001, kernel=rbf;, score=(train=0.901, test=0.759) total time=   0.0s\n",
      "[CV 2/5] END C=2, gamma=0.0001, kernel=rbf;, score=(train=0.882, test=0.806) total time=   0.0s\n",
      "[CV 3/5] END C=2, gamma=0.0001, kernel=rbf;, score=(train=0.887, test=0.837) total time=   0.0s\n",
      "[CV 4/5] END C=2, gamma=0.0001, kernel=rbf;, score=(train=0.895, test=0.678) total time=   0.0s\n",
      "[CV 5/5] END C=2, gamma=0.0001, kernel=rbf;, score=(train=0.878, test=0.808) total time=   0.0s\n",
      "[CV 1/5] END C=2, gamma=0.0001, kernel=sigmoid;, score=(train=0.587, test=0.524) total time=   0.0s\n",
      "[CV 2/5] END C=2, gamma=0.0001, kernel=sigmoid;, score=(train=0.518, test=0.383) total time=   0.0s\n",
      "[CV 3/5] END C=2, gamma=0.0001, kernel=sigmoid;, score=(train=0.620, test=0.561) total time=   0.0s\n",
      "[CV 4/5] END C=2, gamma=0.0001, kernel=sigmoid;, score=(train=0.500, test=0.636) total time=   0.0s\n",
      "[CV 5/5] END C=2, gamma=0.0001, kernel=sigmoid;, score=(train=0.602, test=0.684) total time=   0.0s\n",
      "[CV 1/5] END C=2, gamma=0.0001, kernel=linear;, score=(train=0.745, test=0.752) total time=   7.6s\n",
      "[CV 2/5] END C=2, gamma=0.0001, kernel=linear;, score=(train=0.747, test=0.727) total time=   7.3s\n",
      "[CV 3/5] END C=2, gamma=0.0001, kernel=linear;, score=(train=0.777, test=0.565) total time=  31.4s\n",
      "[CV 4/5] END C=2, gamma=0.0001, kernel=linear;, score=(train=0.742, test=0.737) total time=  18.4s\n",
      "[CV 5/5] END C=2, gamma=0.0001, kernel=linear;, score=(train=0.824, test=0.751) total time=   1.5s\n",
      "[CV 1/5] END C=5, gamma=0.001, kernel=rbf;, score=(train=0.977, test=0.770) total time=   0.0s\n",
      "[CV 2/5] END C=5, gamma=0.001, kernel=rbf;, score=(train=0.980, test=0.801) total time=   0.0s\n",
      "[CV 3/5] END C=5, gamma=0.001, kernel=rbf;, score=(train=0.988, test=0.750) total time=   0.0s\n",
      "[CV 4/5] END C=5, gamma=0.001, kernel=rbf;, score=(train=0.988, test=0.747) total time=   0.0s\n",
      "[CV 5/5] END C=5, gamma=0.001, kernel=rbf;, score=(train=0.988, test=0.702) total time=   0.0s\n",
      "[CV 1/5] END C=5, gamma=0.001, kernel=sigmoid;, score=(train=0.327, test=0.464) total time=   0.0s\n",
      "[CV 2/5] END C=5, gamma=0.001, kernel=sigmoid;, score=(train=0.328, test=0.213) total time=   0.0s\n",
      "[CV 3/5] END C=5, gamma=0.001, kernel=sigmoid;, score=(train=0.317, test=0.231) total time=   0.0s\n",
      "[CV 4/5] END C=5, gamma=0.001, kernel=sigmoid;, score=(train=0.294, test=0.416) total time=   0.0s\n",
      "[CV 5/5] END C=5, gamma=0.001, kernel=sigmoid;, score=(train=0.304, test=0.342) total time=   0.0s\n",
      "[CV 1/5] END C=5, gamma=0.001, kernel=linear;, score=(train=0.729, test=0.752) total time=  22.3s\n",
      "[CV 2/5] END C=5, gamma=0.001, kernel=linear;, score=(train=0.746, test=0.727) total time=  30.5s\n",
      "[CV 3/5] END C=5, gamma=0.001, kernel=linear;, score=(train=0.780, test=0.586) total time=  18.9s\n",
      "[CV 4/5] END C=5, gamma=0.001, kernel=linear;, score=(train=0.742, test=0.737) total time=  38.4s\n",
      "[CV 5/5] END C=5, gamma=0.001, kernel=linear;, score=(train=0.824, test=0.765) total time=   2.8s\n",
      "[CV 1/5] END C=5, gamma=0.0001, kernel=rbf;, score=(train=0.916, test=0.771) total time=   0.0s\n",
      "[CV 2/5] END C=5, gamma=0.0001, kernel=rbf;, score=(train=0.911, test=0.828) total time=   0.0s\n",
      "[CV 3/5] END C=5, gamma=0.0001, kernel=rbf;, score=(train=0.899, test=0.850) total time=   0.0s\n",
      "[CV 4/5] END C=5, gamma=0.0001, kernel=rbf;, score=(train=0.913, test=0.678) total time=   0.0s\n",
      "[CV 5/5] END C=5, gamma=0.0001, kernel=rbf;, score=(train=0.908, test=0.787) total time=   0.0s\n",
      "[CV 1/5] END C=5, gamma=0.0001, kernel=sigmoid;, score=(train=0.548, test=0.516) total time=   0.0s\n",
      "[CV 2/5] END C=5, gamma=0.0001, kernel=sigmoid;, score=(train=0.555, test=0.602) total time=   0.0s\n",
      "[CV 3/5] END C=5, gamma=0.0001, kernel=sigmoid;, score=(train=0.539, test=0.516) total time=   0.0s\n",
      "[CV 4/5] END C=5, gamma=0.0001, kernel=sigmoid;, score=(train=0.493, test=0.622) total time=   0.0s\n",
      "[CV 5/5] END C=5, gamma=0.0001, kernel=sigmoid;, score=(train=0.613, test=0.686) total time=   0.0s\n",
      "[CV 1/5] END C=5, gamma=0.0001, kernel=linear;, score=(train=0.729, test=0.752) total time=  22.3s\n",
      "[CV 2/5] END C=5, gamma=0.0001, kernel=linear;, score=(train=0.746, test=0.727) total time=  31.3s\n",
      "[CV 3/5] END C=5, gamma=0.0001, kernel=linear;, score=(train=0.780, test=0.586) total time=  19.5s\n",
      "[CV 4/5] END C=5, gamma=0.0001, kernel=linear;, score=(train=0.742, test=0.737) total time=  38.0s\n",
      "[CV 5/5] END C=5, gamma=0.0001, kernel=linear;, score=(train=0.824, test=0.765) total time=   2.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 2, 5],\n",
       "                         'gamma': [0.001, 0.0001],\n",
       "                         'kernel': ['rbf', 'sigmoid', 'linear']},\n",
       "             return_train_score=True, scoring='f1_macro', verbose=5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters to Tune\n",
    "params = {\"C\": [.0001, .001,.01,0.1,1,2,5],\n",
    "          \"kernel\":['rbf','sigmoid','linear'],\n",
    "         'gamma': [0.001, 0.0001],}\n",
    "\n",
    "svm_search = GridSearchCV(svm_clf, params, cv=5, return_train_score=True, verbose=5, scoring='f1_macro')\n",
    "\n",
    "svm_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5939e7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.782537 using {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "Mean Training Score: 0.6129832751005507\n",
      "Mean Testing Score: 0.9077006985378953\n",
      "\n",
      "Best Parameter Found:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best Accuracy: %f using %s\" % (svm_search.best_score_, svm_search.best_params_))\n",
    "print(\"Mean Training Score:\", np.mean(svm_search.cv_results_['mean_train_score']))\n",
    "print(\"Mean Testing Score:\", svm_search.score(X, y))\n",
    "print(\"\\nBest Parameter Found:\")\n",
    "svm_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7064d4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, gamma=0.0001)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_search = svm_search.best_estimator_\n",
    "\n",
    "svm_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48904744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.78      0.84        60\n",
      "         1.0       0.84      0.93      0.88        72\n",
      "\n",
      "    accuracy                           0.86       132\n",
      "   macro avg       0.87      0.86      0.86       132\n",
      "weighted avg       0.87      0.86      0.86       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "svm_pred = svm_search.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "svm_report = classification_report(y_test, svm_pred)\n",
    "print(svm_report)\n",
    "post_optimization_precision.append(precision_score(y_true=y_test, y_pred=svm_pred))\n",
    "post_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d275c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2b4992fdd00>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "svm_cm = confusion_matrix(y_test, svm_pred, normalize='all')\n",
    "svm_cmd = ConfusionMatrixDisplay(svm_cm)\n",
    "svm_cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be305ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    svm_search, X_test, y_test, name=\"SVM\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"SVM - 2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d87af5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Fitting and training\n",
    "KNN_clf = KNeighborsClassifier()\n",
    "KNN_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6bb50d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.73      0.79        60\n",
      "         1.0       0.80      0.89      0.84        72\n",
      "\n",
      "    accuracy                           0.82       132\n",
      "   macro avg       0.82      0.81      0.81       132\n",
      "weighted avg       0.82      0.82      0.82       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "KNN_pred = KNN_clf.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "KNN_report = classification_report(y_test, KNN_pred)\n",
    "print(KNN_report)\n",
    "pre_optimization_precision.append(precision_score(y_true=y_test, y_pred=KNN_pred))\n",
    "pre_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=KNN_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bce103c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END n_neighbors=10, p=1, weights=uniform;, score=(train=0.850, test=0.761) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=10, p=1, weights=uniform;, score=(train=0.862, test=0.840) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=10, p=1, weights=uniform;, score=(train=0.853, test=0.759) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=10, p=1, weights=uniform;, score=(train=0.877, test=0.722) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=10, p=1, weights=uniform;, score=(train=0.871, test=0.770) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=10, p=1, weights=distance;, score=(train=1.000, test=0.761) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=10, p=1, weights=distance;, score=(train=1.000, test=0.828) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=10, p=1, weights=distance;, score=(train=1.000, test=0.744) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=10, p=1, weights=distance;, score=(train=1.000, test=0.686) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=10, p=1, weights=distance;, score=(train=1.000, test=0.770) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=10, p=2, weights=uniform;, score=(train=0.842, test=0.749) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=10, p=2, weights=uniform;, score=(train=0.848, test=0.806) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=10, p=2, weights=uniform;, score=(train=0.853, test=0.817) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=10, p=2, weights=uniform;, score=(train=0.867, test=0.779) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=10, p=2, weights=uniform;, score=(train=0.856, test=0.768) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=10, p=2, weights=distance;, score=(train=1.000, test=0.737) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=10, p=2, weights=distance;, score=(train=1.000, test=0.805) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=10, p=2, weights=distance;, score=(train=1.000, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=10, p=2, weights=distance;, score=(train=1.000, test=0.720) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=10, p=2, weights=distance;, score=(train=1.000, test=0.788) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=20, p=1, weights=uniform;, score=(train=0.834, test=0.734) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=20, p=1, weights=uniform;, score=(train=0.855, test=0.828) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=20, p=1, weights=uniform;, score=(train=0.855, test=0.804) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=20, p=1, weights=uniform;, score=(train=0.846, test=0.752) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=20, p=1, weights=uniform;, score=(train=0.847, test=0.792) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=20, p=1, weights=distance;, score=(train=1.000, test=0.724) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=20, p=1, weights=distance;, score=(train=1.000, test=0.838) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=20, p=1, weights=distance;, score=(train=1.000, test=0.779) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=20, p=1, weights=distance;, score=(train=1.000, test=0.765) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=20, p=1, weights=distance;, score=(train=1.000, test=0.779) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=20, p=2, weights=uniform;, score=(train=0.825, test=0.697) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=20, p=2, weights=uniform;, score=(train=0.814, test=0.827) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=20, p=2, weights=uniform;, score=(train=0.794, test=0.781) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=20, p=2, weights=uniform;, score=(train=0.819, test=0.720) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=20, p=2, weights=uniform;, score=(train=0.815, test=0.774) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=20, p=2, weights=distance;, score=(train=1.000, test=0.697) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=20, p=2, weights=distance;, score=(train=1.000, test=0.827) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=20, p=2, weights=distance;, score=(train=1.000, test=0.739) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=20, p=2, weights=distance;, score=(train=1.000, test=0.710) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=20, p=2, weights=distance;, score=(train=1.000, test=0.797) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=50, p=1, weights=uniform;, score=(train=0.828, test=0.707) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=50, p=1, weights=uniform;, score=(train=0.812, test=0.871) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=50, p=1, weights=uniform;, score=(train=0.809, test=0.835) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=50, p=1, weights=uniform;, score=(train=0.801, test=0.705) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=50, p=1, weights=uniform;, score=(train=0.812, test=0.763) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=50, p=1, weights=distance;, score=(train=1.000, test=0.724) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=50, p=1, weights=distance;, score=(train=1.000, test=0.860) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=50, p=1, weights=distance;, score=(train=1.000, test=0.859) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=50, p=1, weights=distance;, score=(train=1.000, test=0.705) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=50, p=1, weights=distance;, score=(train=1.000, test=0.776) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=50, p=2, weights=uniform;, score=(train=0.778, test=0.641) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=50, p=2, weights=uniform;, score=(train=0.752, test=0.860) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=50, p=2, weights=uniform;, score=(train=0.762, test=0.747) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=50, p=2, weights=uniform;, score=(train=0.760, test=0.712) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=50, p=2, weights=uniform;, score=(train=0.760, test=0.719) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=50, p=2, weights=distance;, score=(train=1.000, test=0.664) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=50, p=2, weights=distance;, score=(train=1.000, test=0.871) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=50, p=2, weights=distance;, score=(train=1.000, test=0.810) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=50, p=2, weights=distance;, score=(train=1.000, test=0.712) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=50, p=2, weights=distance;, score=(train=1.000, test=0.744) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=200, p=1, weights=uniform;, score=(train=0.751, test=0.695) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=200, p=1, weights=uniform;, score=(train=0.653, test=0.758) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=200, p=1, weights=uniform;, score=(train=0.696, test=0.600) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=200, p=1, weights=uniform;, score=(train=0.654, test=0.711) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=200, p=1, weights=uniform;, score=(train=0.704, test=0.669) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=200, p=1, weights=distance;, score=(train=1.000, test=0.692) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=200, p=1, weights=distance;, score=(train=1.000, test=0.871) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=200, p=1, weights=distance;, score=(train=1.000, test=0.751) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=200, p=1, weights=distance;, score=(train=1.000, test=0.688) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=200, p=1, weights=distance;, score=(train=1.000, test=0.740) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=200, p=2, weights=uniform;, score=(train=0.615, test=0.621) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=200, p=2, weights=uniform;, score=(train=0.570, test=0.581) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=200, p=2, weights=uniform;, score=(train=0.559, test=0.582) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=200, p=2, weights=uniform;, score=(train=0.560, test=0.600) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=200, p=2, weights=uniform;, score=(train=0.611, test=0.485) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=200, p=2, weights=distance;, score=(train=1.000, test=0.656) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=200, p=2, weights=distance;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=200, p=2, weights=distance;, score=(train=1.000, test=0.681) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=200, p=2, weights=distance;, score=(train=1.000, test=0.705) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=200, p=2, weights=distance;, score=(train=1.000, test=0.633) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END n_neighbors=400, p=1, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=400, p=1, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=400, p=1, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=400, p=1, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=400, p=1, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=400, p=1, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=400, p=1, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=400, p=1, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=400, p=1, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=400, p=1, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=400, p=2, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=400, p=2, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=400, p=2, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=400, p=2, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=400, p=2, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=400, p=2, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=400, p=2, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=400, p=2, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=400, p=2, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=400, p=2, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=600, p=1, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=600, p=1, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=600, p=1, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=600, p=1, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=600, p=1, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=600, p=1, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=600, p=1, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=600, p=1, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=600, p=1, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=600, p=1, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=600, p=2, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=600, p=2, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=600, p=2, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=600, p=2, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=600, p=2, weights=uniform;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/5] END n_neighbors=600, p=2, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/5] END n_neighbors=600, p=2, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/5] END n_neighbors=600, p=2, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/5] END n_neighbors=600, p=2, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/5] END n_neighbors=600, p=2, weights=distance;, score=(train=nan, test=nan) total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [10, 20, 50, 200, 400, 600],\n",
       "                         'p': [1, 2], 'weights': ['uniform', 'distance']},\n",
       "             return_train_score=True, scoring='f1_macro', verbose=5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters to Tune\n",
    "params = {\"n_neighbors\": [10, 20, 50, 200, 400, 600],\n",
    "          \"weights\": ['uniform', 'distance'],\n",
    "          \"p\": [1,2]}\n",
    "\n",
    "KNN_search = GridSearchCV(KNN_clf, params, cv=5, return_train_score=True, verbose=5, scoring='f1_macro')\n",
    "\n",
    "KNN_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1bfe888b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.784678 using {'n_neighbors': 50, 'p': 1, 'weights': 'distance'}\n",
      "Mean Training Score: nan\n",
      "Mean Testing Score: 1.0\n",
      "\n",
      "Best Parameter Found:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 50, 'p': 1, 'weights': 'distance'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best Accuracy: %f using %s\" % (KNN_search.best_score_, KNN_search.best_params_))\n",
    "print(\"Mean Training Score:\", np.mean(KNN_search.cv_results_['mean_train_score']))\n",
    "print(\"Mean Testing Score:\", KNN_search.score(X, y))\n",
    "print(\"\\nBest Parameter Found:\")\n",
    "KNN_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51b56d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        60\n",
      "         1.0       1.00      1.00      1.00        72\n",
      "\n",
      "    accuracy                           1.00       132\n",
      "   macro avg       1.00      1.00      1.00       132\n",
      "weighted avg       1.00      1.00      1.00       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "KNN_pred = KNN_search.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "KNN_report = classification_report(y_test, KNN_pred)\n",
    "print(KNN_report)\n",
    "post_optimization_precision.append(precision_score(y_true=y_test, y_pred=KNN_pred))\n",
    "post_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=KNN_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87deaef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2b49940cf10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "KNN_cm = confusion_matrix(y_test, KNN_pred, normalize='all')\n",
    "KNN_cmd = ConfusionMatrixDisplay(KNN_cm)\n",
    "KNN_cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "417e9c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    KNN_search, X_test, y_test, name=\"KNN\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"KNN - 2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "429dffd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fitting and training\n",
    "RFC_clf = RandomForestClassifier()\n",
    "RFC_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "814771d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.88      0.90        60\n",
      "         1.0       0.91      0.93      0.92        72\n",
      "\n",
      "    accuracy                           0.91       132\n",
      "   macro avg       0.91      0.91      0.91       132\n",
      "weighted avg       0.91      0.91      0.91       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "RFC_pred = RFC_clf.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "RFC_report = classification_report(y_test, RFC_pred)\n",
    "print(RFC_report)\n",
    "pre_optimization_precision.append(precision_score(y_true=y_test, y_pred=RFC_pred))\n",
    "pre_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=RFC_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d06525c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.954) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.829) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.797) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.986, test=0.904) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.985, test=0.880) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.953) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.861) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.994, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.870) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.929) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.874) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.892) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.919) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.897) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.885) total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.941) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.965, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.801) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.983, test=0.954) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.843) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.991, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=1.000, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.994, test=0.908) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.907) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.994, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.929) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.862) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.874) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.931) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.896) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.991, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.991, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.918) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.885) total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.919) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.994, test=0.941) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.980, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.818) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.849) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.905) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.834) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.862) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.840) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.991, test=0.884) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.994, test=0.858) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.908) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.994, test=0.880) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.997, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.997, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.908) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.997, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.918) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.885) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.885) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.941) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.994, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.977, test=0.896) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.962, test=0.828) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.980, test=0.790) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.977, test=0.893) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.880) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.994, test=0.906) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.994, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.885) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.977, test=0.872) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.985, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.919) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.873) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.918) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.985, test=0.892) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.885) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.965) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.988, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.991, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.931) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.908) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.991, test=0.929) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.985, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.965, test=0.874) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.959, test=0.852) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.971, test=0.886) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.974, test=0.843) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.968, test=0.834) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.968, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.983, test=0.907) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.980, test=0.873) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.971, test=0.942) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.971, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.908) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.848) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.991, test=0.965) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.980, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.980, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.991, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.985, test=0.908) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.985, test=0.892) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.968, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.974, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.908) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.988, test=0.908) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.980, test=0.929) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.980, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.951, test=0.852) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.971, test=0.895) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.983, test=0.776) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.971, test=0.893) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.965, test=0.855) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.959, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.919) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.885) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.954) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.974, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.986, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.974, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.983, test=0.843) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.977, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.988, test=0.860) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.983, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.983, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.971, test=0.895) total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.974, test=0.907) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.988, test=0.907) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.983, test=0.941) total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.980, test=0.866) total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.866, test=0.808) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.912, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.914, test=0.740) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.883, test=0.856) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.924, test=0.812) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.900, test=0.861) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.914, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.926, test=0.779) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.912, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.911, test=0.826) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.911, test=0.871) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.908, test=0.895) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.926, test=0.760) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.901, test=0.830) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.941, test=0.841) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.896, test=0.882) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.926, test=0.931) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.908, test=0.711) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.908, test=0.853) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.947, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.899, test=0.870) total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.920, test=0.907) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.932, test=0.776) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.921, test=0.917) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.944, test=0.839) total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.893, test=0.917) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.899, test=0.843) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.908, test=0.882) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.881, test=0.837) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.924, test=0.858) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.900, test=0.826) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.905, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.905, test=0.686) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.923, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.911, test=0.839) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.924, test=0.838) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.913, test=0.930) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.926, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.894, test=0.881) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.932, test=0.839) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.880, test=0.882) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.917, test=0.919) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.917, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.907, test=0.866) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.932, test=0.826) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.902, test=0.870) total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.926, test=0.930) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.917, test=0.754) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.915, test=0.904) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.944, test=0.853) total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.840, test=0.705) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.877, test=0.860) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.904, test=0.765) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.907, test=0.918) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.932, test=0.812) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.903, test=0.848) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.935, test=0.918) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.923, test=0.751) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.893, test=0.851) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.920, test=0.841) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.885, test=0.860) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.923, test=0.941) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.929, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.903, test=0.853) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.935, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.902, test=0.882) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.932, test=0.895) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.929, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.914, test=0.892) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.935, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.877, test=0.882) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.920, test=0.907) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.920, test=0.804) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.905, test=0.929) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.932, test=0.853) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.905, test=0.881) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.899, test=0.895) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.894, test=0.750) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.916, test=0.908) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.922, test=0.847) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.893, test=0.893) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.938, test=0.941) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.923, test=0.776) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.899, test=0.841) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.944, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.881, test=0.882) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.894, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.905, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.912, test=0.866) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.941, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.911, test=0.882) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.905, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.926, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.899, test=0.892) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.938, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.909, test=0.859) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.923, test=0.918) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.920, test=0.779) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.906, test=0.917) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.938, test=0.839) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.886, test=0.905) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.865, test=0.807) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.902, test=0.832) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.865, test=0.790) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.912, test=0.787) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.900, test=0.838) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.908, test=0.883) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.923, test=0.776) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.900, test=0.826) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.926, test=0.826) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.911, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.923, test=0.942) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.941, test=0.895) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.902, test=0.839) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.935, test=0.839) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.902, test=0.871) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.917, test=0.895) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.926, test=0.765) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.905, test=0.855) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.935, test=0.839) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.915, test=0.871) total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.920, test=0.895) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.923, test=0.776) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.912, test=0.904) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.941, test=0.853) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.869, test=0.760) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.890, test=0.824) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.898, test=0.776) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.878, test=0.798) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.932, test=0.828) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.888, test=0.861) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.920, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.920, test=0.758) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.917, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.911, test=0.841) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.890, test=0.813) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.920, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.901, test=0.772) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.896, test=0.892) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.914, test=0.841) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.874, test=0.870) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.911, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.917, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.905, test=0.893) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.944, test=0.839) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.890, test=0.861) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.914, test=0.919) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.913, test=0.765) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.918, test=0.917) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.944, test=0.853) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.974, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.985, test=0.884) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.971, test=0.860) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.968, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.974, test=0.869) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.977, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.971, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.983, test=0.885) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.977, test=0.931) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.980, test=0.841) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.983, test=0.906) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.977, test=0.863) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.991, test=0.848) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.907) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.830) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.980, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.985, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.991, test=0.895) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.991, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.980, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.983, test=0.918) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.991, test=0.896) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.885) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.983, test=0.917) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.956, test=0.905) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.965, test=0.861) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.962, test=0.768) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.956, test=0.847) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.968, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.977, test=0.873) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.971, test=0.931) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.980, test=0.787) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.977, test=0.881) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.980, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.983, test=0.851) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.896) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.983, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.983, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.988, test=0.863) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.985, test=0.862) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.985, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.974, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.980, test=0.885) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.983, test=0.883) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.971, test=0.953) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.980, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.906) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.965, test=0.860) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.968, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.980, test=0.845) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.974, test=0.885) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.983, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.983, test=0.774) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.971, test=0.882) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.983, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.983, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.980, test=0.919) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.994, test=0.874) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.980, test=0.930) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.856) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.991, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.983, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.994, test=0.837) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.983, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.985, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.988, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.988, test=0.930) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.988, test=0.883) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.917) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.983, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.965, test=0.929) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.956, test=0.851) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.950, test=0.750) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.948, test=0.856) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.977, test=0.834) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.968, test=0.917) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.977, test=0.920) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.974, test=0.838) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.974, test=0.855) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.983, test=0.897) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.983, test=0.896) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.980, test=0.904) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.962, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.977, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.983, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.983, test=0.873) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.974, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.983, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.983, test=0.907) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.985, test=0.896) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.977, test=0.917) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.974, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.944, test=0.906) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.953, test=0.920) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.956, test=0.741) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.971, test=0.930) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.971, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.959, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.947, test=0.863) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.962, test=0.784) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.980, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.971, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.980, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.974, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.974, test=0.778) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.962, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.974, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.965, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.977, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.971, test=0.884) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.977, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.980, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.977, test=0.918) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.977, test=0.897) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.980, test=0.872) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.974, test=0.977) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.977, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.942, test=0.874) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.968, test=0.931) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.947, test=0.930) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.953, test=0.880) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.971, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.971, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.968, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.838) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.965, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.974, test=0.856) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.971, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.983, test=0.908) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.971, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.974, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.971, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.977, test=0.885) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.871) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.971, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.977, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.977, test=0.907) total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.977, test=0.885) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.980, test=0.895) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.977, test=0.941) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.980, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.929) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.886) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.942) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.873) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.885) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.894) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.880) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.885) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.856) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.885) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.930) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.908) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.874) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.941) total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.968, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.983, test=0.816) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.994, test=0.977) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.986, test=0.858) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.919) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.997, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.997, test=0.815) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.919) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.994, test=0.834) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.855) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.991, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.907) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.885) total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.908) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.953) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.980, test=0.885) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.863) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.980, test=0.896) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.980, test=0.856) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.929) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.994, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.994, test=0.883) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.994, test=0.856) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.907) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.965) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.991, test=0.855) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.994, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.997, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.885) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.997, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.997, test=0.918) total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.997, test=0.885) total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.897) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.941) total time=   0.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.997, test=0.879) total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.977, test=0.883) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.974, test=0.828) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.962, test=0.720) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.983, test=0.907) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.904) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.994, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.991, test=0.874) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.985, test=0.965) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.985, test=0.897) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.931) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.983, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.919) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.988, test=0.874) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.988, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.991, test=0.918) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.885) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.908) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.991, test=0.941) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.991, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.968, test=0.850) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.953, test=0.818) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.962, test=0.734) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.965, test=0.867) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.965, test=0.823) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.962, test=0.872) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.985, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.983, test=0.885) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.977, test=0.965) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.983, test=0.880) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.977, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.907) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.873) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.980, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.977, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.974, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.983, test=0.909) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.988, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.980, test=0.905) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.977, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.977, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.897) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.991, test=0.896) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.953) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.977, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.971, test=0.861) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.965, test=0.872) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.974, test=0.819) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.977, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.974, test=0.834) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.965, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.977, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.873) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.974, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.980, test=0.855) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.974, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.863) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.985, test=0.840) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.985, test=0.904) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.983, test=0.843) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.985, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.985, test=0.907) total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.977, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.968, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.980, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.988, test=0.896) total time=   0.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.991, test=0.896) total time=   0.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.988, test=0.941) total time=   0.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.983, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.893) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.840) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.828) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.858) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.906) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.850) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.942) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.907) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.904) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.918) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.897) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.908) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.942) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.879) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.977, test=0.882) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.994, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.884) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.986, test=0.894) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.986, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.886) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.862) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.997, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=1.000, test=0.880) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.863) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.893) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.892) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.918) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.885) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.919) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.994, test=0.953) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.983, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.931) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=1.000, test=0.848) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.845) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.869) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.994, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.907) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.874) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.866) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.907) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.917) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.919) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.942) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.994, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.919) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.908) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.920) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.941) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.962, test=0.883) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.986, test=0.864) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.856) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.941) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.991, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.991, test=0.885) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.991, test=0.954) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.985, test=0.856) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.929) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.920) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.855) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.988, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.919) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.988) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.918) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.896) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.908) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.941) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.994, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.965, test=0.871) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.828) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.974, test=0.849) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.985, test=0.930) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.977, test=0.832) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.971, test=0.919) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.980, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.980, test=0.884) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.980, test=0.942) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.977, test=0.869) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.991, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.988, test=0.851) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.971, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.985, test=0.906) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.985, test=0.908) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.991, test=0.862) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.985, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.980, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.907) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.885) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.920) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.988, test=0.965) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.968, test=0.884) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.965, test=0.872) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.962, test=0.884) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.971, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.971, test=0.841) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.991, test=0.931) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.931) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.908) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.881) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.980, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.980, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.980, test=0.907) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.907) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.977, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.931) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.931) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.983, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.985, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.985, test=0.885) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.988, test=0.895) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.988, test=0.953) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.980, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.857, test=0.848) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.889, test=0.869) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.915, test=0.837) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.830, test=0.853) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.909, test=0.841) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.921, test=0.812) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.908, test=0.862) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.914, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.900, test=0.856) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.932, test=0.828) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.927, test=0.860) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.917, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.908, test=0.740) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.912, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.947, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.905, test=0.849) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.914, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.920, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.932, test=0.917) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.938, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.909, test=0.882) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.917, test=0.907) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.923, test=0.754) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.920, test=0.917) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.914, test=0.839) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.864, test=0.870) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.917, test=0.855) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.867, test=0.808) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.885, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.902, test=0.815) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.887, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.929, test=0.918) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.920, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.913, test=0.861) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.895, test=0.812) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.884, test=0.848) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.914, test=0.882) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.923, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.905, test=0.866) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.923, test=0.839) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.883, test=0.905) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.920, test=0.930) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.920, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.917, test=0.904) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.933, test=0.839) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.871, test=0.871) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.932, test=0.930) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.914, test=0.754) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.923, test=0.917) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.932, test=0.853) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.860, test=0.806) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.953, test=0.965) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.860, test=0.726) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.901, test=0.892) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.866, test=0.815) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.869, test=0.826) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.912, test=0.828) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.905, test=0.776) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.902, test=0.905) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.895, test=0.828) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.893, test=0.837) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.908, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.920, test=0.740) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.908, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.938, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.902, test=0.849) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.926, test=0.918) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.926, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.902, test=0.892) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.938, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.909, test=0.837) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.910, test=0.919) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.920, test=0.754) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.911, test=0.917) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.941, test=0.853) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.895, test=0.861) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.883, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.905, test=0.747) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.863, test=0.879) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.880, test=0.790) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.912, test=0.862) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.926, test=0.882) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.920, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.905, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.932, test=0.839) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.871, test=0.849) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.908, test=0.907) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.917, test=0.751) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.885, test=0.866) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.932, test=0.804) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.912, test=0.848) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.914, test=0.919) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.911, test=0.726) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.929, test=0.904) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.929, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.905, test=0.882) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.911, test=0.919) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.923, test=0.740) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.917, test=0.879) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.944, test=0.853) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.851, test=0.856) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.915, test=0.861) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.908, test=0.744) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.856, test=0.892) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.918, test=0.830) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.852, test=0.881) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.907, test=0.858) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.902, test=0.716) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.881, test=0.907) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.941, test=0.841) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.884, test=0.871) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.911, test=0.882) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.932, test=0.765) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.901, test=0.826) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.935, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.883, test=0.881) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.911, test=0.884) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.920, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.912, test=0.918) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.944, test=0.839) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.899, test=0.882) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.914, test=0.896) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.923, test=0.765) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.905, test=0.904) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.950, test=0.866) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.788, test=0.797) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.914, test=0.883) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.855, test=0.717) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.826, test=0.727) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.883, test=0.830) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.915, test=0.860) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.911, test=0.823) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.905, test=0.744) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.885, test=0.866) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.926, test=0.839) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.917, test=0.881) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.913, test=0.906) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.911, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.927, test=0.904) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.941, test=0.826) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.899, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.917, test=0.907) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.917, test=0.754) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.926, test=0.892) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.932, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.899, test=0.870) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.914, test=0.919) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.929, test=0.765) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.911, test=0.904) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.938, test=0.839) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.959, test=0.862) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.977, test=0.920) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.971, test=0.834) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.985, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.971, test=0.808) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.980, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.980, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.985, test=0.908) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.983, test=0.977) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.985, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.977, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.983, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.919) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.983, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=0.983, test=0.843) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.991, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.985, test=0.896) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.977, test=0.884) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.985, test=0.953) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=0.977, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.983, test=0.918) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.908) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.983, test=0.896) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.983, test=0.977) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=0.985, test=0.879) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.936, test=0.859) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.944, test=0.919) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.965, test=0.837) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.974, test=0.965) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.962, test=0.828) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.962, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.985, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.873) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.974, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.968, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.965, test=0.907) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.971, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.810) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.985, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.980, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.983, test=0.873) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.971, test=0.879) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.977, test=0.855) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.983, test=0.907) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.983, test=0.919) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.983, test=0.920) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.988, test=0.988) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.980, test=0.866) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.974, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.971, test=0.918) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.974, test=0.884) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.968, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.985, test=0.906) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.968, test=0.919) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.988, test=0.793) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.977, test=0.977) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.971, test=0.892) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.983, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.931) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.980, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.983, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.983, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.983, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.991, test=0.884) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.985, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.980, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.983, test=0.918) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.988, test=0.897) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.991, test=0.919) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.988, test=0.941) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=0.983, test=0.866) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.974, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.959, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.980, test=0.885) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.956, test=0.855) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.962, test=0.810) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.980, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.980, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.977, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.971, test=0.893) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.884) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.974, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.974, test=0.826) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.968, test=0.866) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.895) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.977, test=0.907) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.977, test=0.965) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.879) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.977, test=0.907) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.980, test=0.896) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.977, test=0.907) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.980, test=0.953) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.974, test=0.866) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.956, test=0.882) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.950, test=0.886) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.962, test=0.884) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.971, test=0.871) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.968, test=0.828) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.956, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.965, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.977, test=0.896) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.974, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.968, test=0.892) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.965, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.980, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.974, test=0.907) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.959, test=0.904) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.974, test=0.892) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.971, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.968, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.965, test=0.907) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.974, test=0.965) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.971, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.956, test=0.907) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.977, test=0.896) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.974, test=0.896) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.977, test=0.953) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.971, test=0.866) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.939, test=0.840) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.956, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.956, test=0.848) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.959, test=0.965) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.965, test=0.832) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.965, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.965, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.974, test=0.848) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.985, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.971, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.977, test=0.895) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.965, test=0.823) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.968, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.968, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.971, test=0.907) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.971, test=0.896) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.977, test=0.872) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.980, test=0.953) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.974, test=0.866) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.971, test=0.907) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.983, test=0.908) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.968, test=0.896) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.977, test=0.953) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.971, test=0.866) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.908) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.793) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.985, test=0.931) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.856) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.919) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.853) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.884) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.896) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.885) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.930) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.897) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.908) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.953) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.904) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.974, test=0.885) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.931) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.835) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.882) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.806) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.991, test=0.917) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.997, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.872) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.994, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=25;, score=(train=0.988, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.908) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.869) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.907) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.885) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.908) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.941) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.866) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.919) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.874) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.896) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.819) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=1.000, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.909) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.997, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=25;, score=(train=0.994, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.872) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.880) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.930) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.997, test=0.931) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100;, score=(train=0.997, test=0.904) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.930) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.885) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.908) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.953) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=(train=1.000, test=0.879) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.977, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.983, test=0.845) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.832) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.985, test=0.930) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.994, test=0.907) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.994, test=0.896) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=25;, score=(train=0.985, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.931) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=1.000, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.866) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.919) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=1.000, test=0.919) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.953) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100;, score=(train=0.991, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.991, test=0.918) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.897) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=1.000, test=0.919) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.997, test=0.941) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200;, score=(train=0.991, test=0.892) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.968, test=0.906) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.974, test=0.885) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.974, test=0.826) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.968, test=0.894) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10;, score=(train=0.968, test=0.830) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.968, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.974, test=0.851) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.980, test=0.812) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.977, test=0.965) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=25;, score=(train=0.977, test=0.843) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.985, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.983, test=0.874) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.991, test=0.838) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.983, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50;, score=(train=0.980, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.991, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.988, test=0.896) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.983, test=0.897) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.983, test=0.941) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=100;, score=(train=0.988, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.983, test=0.918) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.991, test=0.908) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.994, test=0.908) total time=   0.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.983, test=0.965) total time=   0.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=200;, score=(train=0.977, test=0.879) total time=   0.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.971, test=0.895) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.974, test=0.942) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.965, test=0.790) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.882) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=10;, score=(train=0.968, test=0.841) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.974, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.980, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.985, test=0.871) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.929) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=25;, score=(train=0.983, test=0.867) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.985, test=0.907) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.863) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.908) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.985, test=0.930) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=50;, score=(train=0.983, test=0.855) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.985, test=0.918) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.908) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.985, test=0.884) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.988, test=0.917) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=100;, score=(train=0.985, test=0.879) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.988, test=0.918) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.985, test=0.896) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.994, test=0.908) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.985, test=0.953) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, n_estimators=200;, score=(train=0.977, test=0.866) total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 5, 10],\n",
       "                         'min_samples_leaf': [1, 2, 5],\n",
       "                         'min_samples_split': [5, 10],\n",
       "                         'n_estimators': [10, 25, 50, 100, 200]},\n",
       "             return_train_score=True, scoring='f1_macro', verbose=5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters to Tune\n",
    "params = {'n_estimators': [10,25,50,100,200],\n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 2, 5, 10],\n",
    "          'min_samples_split': [5,10],\n",
    "          'min_samples_leaf': [1, 2, 5]}\n",
    "\n",
    "RFC_search = GridSearchCV(RFC_clf, params, cv=5, return_train_score=True, verbose=5, scoring='f1_macro')\n",
    "\n",
    "RFC_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c60d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.919848 using {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Mean Training Score: 0.9660377704774639\n",
      "Mean Testing Score: 0.976682564917859\n",
      "\n",
      "Best Parameter Found:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best Accuracy: %f using %s\" % (RFC_search.best_score_, RFC_search.best_params_))\n",
    "print(\"Mean Training Score:\", np.mean(RFC_search.cv_results_['mean_train_score']))\n",
    "print(\"Mean Testing Score:\", RFC_search.score(X, y))\n",
    "print(\"\\nBest Parameter Found:\")\n",
    "RFC_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "715d49de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=5, min_samples_split=10,\n",
       "                       n_estimators=200)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_search = RFC_search.best_estimator_\n",
    "\n",
    "RFC_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2074aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.87      0.90        60\n",
      "         1.0       0.90      0.96      0.93        72\n",
      "\n",
      "    accuracy                           0.92       132\n",
      "   macro avg       0.92      0.91      0.92       132\n",
      "weighted avg       0.92      0.92      0.92       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "RFC_pred = RFC_search.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "RFC_report = classification_report(y_test, RFC_pred)\n",
    "print(RFC_report)\n",
    "post_optimization_precision.append(precision_score(y_true=y_test, y_pred=RFC_pred))\n",
    "post_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=RFC_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a0434c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2b499574520>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "RFC_cm = confusion_matrix(y_test, RFC_pred, normalize='all')\n",
    "RFC_cmd = ConfusionMatrixDisplay(RFC_cm)\n",
    "RFC_cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d289fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    RFC_search, X_test, y_test, name=\"Random Forest\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"Random Forest - 2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7250c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "794e089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "\n",
    "from sklearn.base import clone\n",
    " \n",
    "def create_keras_classifier_model(n_classes):\n",
    "    \"\"\"Keras multinomial logistic regression creation model\n",
    " \n",
    "    Args:\n",
    "        n_classes(int): Number of classes to be classified\n",
    " \n",
    "    Returns:\n",
    "        Compiled keras model\n",
    " \n",
    "    \"\"\"\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=len(X.columns), activation='relu', kernel_initializer='normal'))\n",
    "    model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    " \n",
    "estimator = KerasClassifier(build_fn=create_keras_classifier_model, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78b9f460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 3.5956 - accuracy: 0.7468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.48      0.57        60\n",
      "         1.0       0.66      0.83      0.74        72\n",
      "\n",
      "    accuracy                           0.67       132\n",
      "   macro avg       0.68      0.66      0.66       132\n",
      "weighted avg       0.68      0.67      0.66       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "# Classifier predictions\n",
    "NN_pred = estimator.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "NN_report = classification_report(y_test, NN_pred)\n",
    "print(NN_report)\n",
    "pre_optimization_precision.append(precision_score(y_true=y_test, y_pred=NN_pred))\n",
    "pre_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=NN_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "572e5e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.3726 - accuracy: 0.5932\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.8745 - accuracy: 0.7091\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.7993 - accuracy: 0.7432\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7614\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7682\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 988us/step - loss: 0.5377 - accuracy: 0.7932\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5966 - accuracy: 0.7909\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 963us/step - loss: 0.4564 - accuracy: 0.7977\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.8091\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.8114\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5277 - accuracy: 0.8205\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4290 - accuracy: 0.8159\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.8227\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3935 - accuracy: 0.8295\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4177 - accuracy: 0.8159\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.8318\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.8318\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.8227\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4091 - accuracy: 0.8250\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3995 - accuracy: 0.8364\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8318\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.8136\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4031 - accuracy: 0.8523\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.8364\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.8432\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.8500\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.8318\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8477\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6888 - accuracy: 0.8341\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4195 - accuracy: 0.8409\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 977us/step - loss: 0.3831 - accuracy: 0.8318\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 926us/step - loss: 0.4700 - accuracy: 0.8545\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.8273\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.8341\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 989us/step - loss: 0.5215 - accuracy: 0.8432\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8545\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3673 - accuracy: 0.8409\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8341\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.8455\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.8477\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8477\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.8318\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.8227\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.8364\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5469 - accuracy: 0.8295\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3689 - accuracy: 0.8545\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4148 - accuracy: 0.8341\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3907 - accuracy: 0.8205\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8341\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8432\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3439 - accuracy: 0.8500\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8432\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8477\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.8455\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8364\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.8341\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3847 - accuracy: 0.8409\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8523\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8523\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8568\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4131 - accuracy: 0.8386\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5973 - accuracy: 0.8364\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.8409\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8523\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8386\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.8477\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4200 - accuracy: 0.8455\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8455\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.8500\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8432\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6701 - accuracy: 0.8432\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.8455\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.8386\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8477\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8500\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8545\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8568\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8523\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8477\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8386\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8545\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8591\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8591\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.8500\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8591\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4137 - accuracy: 0.8500\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3700 - accuracy: 0.8523\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8568\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3785 - accuracy: 0.8545\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8591\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3117 - accuracy: 0.8614\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8636\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8682\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6182 - accuracy: 0.8659\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8591\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8591\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.8591\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8636\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.8523\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8568\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8659\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8682\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.8614\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.8705\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4383 - accuracy: 0.8477\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.8659\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.8614\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8682\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2904 - accuracy: 0.8750\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.8614\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 945us/step - loss: 0.3268 - accuracy: 0.8636\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8614\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8659\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8500\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.8591\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2951 - accuracy: 0.8750\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3041 - accuracy: 0.8659\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8659\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.8568\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 989us/step - loss: 0.4961 - accuracy: 0.8705\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8682\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8659\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.8750\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.8659\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 953us/step - loss: 0.4914 - accuracy: 0.8636\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4087 - accuracy: 0.8773\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8545\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8591\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.8705\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8727\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8659\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3043 - accuracy: 0.8659\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8659\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2918 - accuracy: 0.8591\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8659\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8659\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2857 - accuracy: 0.8795\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8659\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8727\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3443 - accuracy: 0.8841\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8727\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8659\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8750\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2965 - accuracy: 0.8682\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2764 - accuracy: 0.8705\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8818\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8795\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3093 - accuracy: 0.8864\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8636\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.8591\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5541 - accuracy: 0.8659\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8636\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2826 - accuracy: 0.8886\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.8909\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8864\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2862 - accuracy: 0.8886\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.8886\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2824 - accuracy: 0.8909\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2654 - accuracy: 0.8841\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2849 - accuracy: 0.8909\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2684 - accuracy: 0.8955\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.8932\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2598 - accuracy: 0.9000\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.8864\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2725 - accuracy: 0.9045\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2894 - accuracy: 0.8818\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2614 - accuracy: 0.8841\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2531 - accuracy: 0.9000\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.8977\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.8864\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 999us/step - loss: 0.2581 - accuracy: 0.8932\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 986us/step - loss: 0.3909 - accuracy: 0.8818\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8750\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8886\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8886\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.9068\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.8977\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.9068\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2952 - accuracy: 0.9000\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8818\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.9045\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.9023\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8909\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2748 - accuracy: 0.8841\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.8818\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.8909\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2526 - accuracy: 0.8932\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 965us/step - loss: 0.2893 - accuracy: 0.9068\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3177 - accuracy: 0.9045\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.9045\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2920 - accuracy: 0.9000\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2766 - accuracy: 0.8909\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2871 - accuracy: 0.8909\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9045\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.9000\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2803 - accuracy: 0.8977\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2360 - accuracy: 0.9045\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2898 - accuracy: 0.9045\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 966us/step - loss: 0.3083 - accuracy: 0.9114\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.9136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000002B4998A8100>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'batch_size': [5, 10, 20, 30, 40, 50],\n",
       "                         'epochs': [100, 125, 150, 175, 200]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters to Tune\n",
    "params = {'epochs': [100,125,150,175,200],\n",
    "          'batch_size': [5,10,20,30,40,50]}\n",
    "\n",
    "NN_search = GridSearchCV(estimator=estimator, param_grid=params, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "\n",
    "NN_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eb407518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.827273 using {'batch_size': 40, 'epochs': 200}\n",
      "Mean Test Score: 0.8096212121212122\n",
      "Mean Std. Test Score: 0.04372013744806823\n",
      "\n",
      "Best Parameter Found:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'batch_size': 40, 'epochs': 200}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best Accuracy: %f using %s\" % (NN_search.best_score_, NN_search.best_params_))\n",
    "print(\"Mean Test Score:\", np.mean(NN_search.cv_results_['mean_test_score']))\n",
    "print(\"Mean Std. Test Score:\", np.mean(NN_search.cv_results_['std_test_score']))\n",
    "print(\"\\nBest Parameter Found:\")\n",
    "NN_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c33ceb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5.2697 - accuracy: 0.5909\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 3.2528 - accuracy: 0.5909\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1.8171 - accuracy: 0.6331\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1.2551 - accuracy: 0.6721\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.8817 - accuracy: 0.6981\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5971 - accuracy: 0.7630\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7695\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7727\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7890\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7890\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.7987\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.8117\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.8149\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.8214\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.8084\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.8182\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.8377\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.8214\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.8247\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8409\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8442\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4021 - accuracy: 0.8247\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3464 - accuracy: 0.8247\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8442\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8539\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8279\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3985 - accuracy: 0.8409\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.8377\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8377\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8279\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8571\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8279\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8344\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8506\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8539\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8409\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 990us/step - loss: 0.3629 - accuracy: 0.8474\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.8442\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8636\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8604\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3752 - accuracy: 0.8409\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.8766\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.8377\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5436 - accuracy: 0.8506\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.8669\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8506\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8539\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.8442\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8506\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.5719 - accuracy: 0.8571\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4199 - accuracy: 0.8506\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8474\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8669\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8539\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8604\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3866 - accuracy: 0.8571\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8474\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3149 - accuracy: 0.8604\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8669\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8506\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8636\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8701\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8669\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8604\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8734\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3513 - accuracy: 0.8669\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8636\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8701\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.8766\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2980 - accuracy: 0.8766\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3069 - accuracy: 0.8636\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.8669\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 978us/step - loss: 0.3162 - accuracy: 0.8701\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.8766\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.8799\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2714 - accuracy: 0.8864\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2965 - accuracy: 0.8701\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3069 - accuracy: 0.8734\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8799\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8766\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8831\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.8831\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8831\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8766\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8799\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.8636\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.8766\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8831\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.8831\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2826 - accuracy: 0.8831\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8766\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3237 - accuracy: 0.8799\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2856 - accuracy: 0.8864\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8701\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8864\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8734\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2604 - accuracy: 0.8961\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2658 - accuracy: 0.8864\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2886 - accuracy: 0.8831\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2810 - accuracy: 0.8864\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8799\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2911 - accuracy: 0.8831\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8766\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8896\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.8994\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2697 - accuracy: 0.8929\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2567 - accuracy: 0.8831\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2639 - accuracy: 0.8864\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8994\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8929\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8864\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8896\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8896\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2421 - accuracy: 0.8961\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2715 - accuracy: 0.8961\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2613 - accuracy: 0.8994\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2617 - accuracy: 0.8864\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8831\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8896\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.9058\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2810 - accuracy: 0.8929\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.8929\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.9026\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3163 - accuracy: 0.8864\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2744 - accuracy: 0.9026\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8994\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2971 - accuracy: 0.8961\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.8994\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.8929\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2962 - accuracy: 0.8929\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.9026\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.9058\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.9058\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8929\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2407 - accuracy: 0.8929\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2677 - accuracy: 0.8961\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.8961\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.9058\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.9026\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.8864\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2906 - accuracy: 0.9058\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3071 - accuracy: 0.9091\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2804 - accuracy: 0.9026\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2802 - accuracy: 0.8994\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2887 - accuracy: 0.8994\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2846 - accuracy: 0.9026\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.9156\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.9058\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.8961\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8961\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 974us/step - loss: 0.3184 - accuracy: 0.9091\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2432 - accuracy: 0.9123\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.9058\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2632 - accuracy: 0.9156\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.8994\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.9091\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2811 - accuracy: 0.9156\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2809 - accuracy: 0.8929\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2558 - accuracy: 0.9091\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9091\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.9221\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2196 - accuracy: 0.9091\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2439 - accuracy: 0.9058\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3039 - accuracy: 0.8961\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.9253\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2951 - accuracy: 0.8994\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.8896\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.9156\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2504 - accuracy: 0.9058\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3131 - accuracy: 0.9123\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9156\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2820 - accuracy: 0.9058\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2859 - accuracy: 0.9123\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.9123\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.9123\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9123\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.9221\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9188\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.9123\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.9156\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2500 - accuracy: 0.9156\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.9221\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9188\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.9221\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2377 - accuracy: 0.9286\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2541 - accuracy: 0.9156\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9221\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.9253\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.9286\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.9253\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.9123\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2978 - accuracy: 0.9221\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.9026\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.9188\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.9286\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.9253\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2316 - accuracy: 0.9221\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.9123\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.9156\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 968us/step - loss: 0.2198 - accuracy: 0.9221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b4992d8760>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_search = NN_search.best_estimator_\n",
    "\n",
    "NN_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "12ed6b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.85      0.84        60\n",
      "         1.0       0.87      0.85      0.86        72\n",
      "\n",
      "    accuracy                           0.85       132\n",
      "   macro avg       0.85      0.85      0.85       132\n",
      "weighted avg       0.85      0.85      0.85       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classifier predictions\n",
    "NN_pred = NN_search.predict(X_test)\n",
    "\n",
    "#Printing out results\n",
    "NN_report = classification_report(y_test, NN_pred)\n",
    "print(NN_report)\n",
    "post_optimization_precision.append(precision_score(y_true=y_test, y_pred=NN_pred))\n",
    "post_optimization_accuracy.append(accuracy_score(y_true=y_test, y_pred=NN_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c31e8c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2b49989d730>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "NN_cm = confusion_matrix(y_test, NN_pred, normalize='all')\n",
    "NN_cmd = ConfusionMatrixDisplay(NN_cm)\n",
    "NN_cmd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2383a01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display = PrecisionRecallDisplay.from_predictions(y_test, NN_pred, name=\"Neural Network\")\n",
    "_ = display.ax_.set_title(\"Neural Network - 2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b3e1451c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2880x360 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "classifiers = {\n",
    "    \"Neural Network\": NN_cm,\n",
    "    \"Logisitic Regression\": LogReg_cm,\n",
    "    \"KNearest\": KNN_cm,\n",
    "    \"Support Vector Classifier\": svm_cm,\n",
    "    \"AdaBoost\": AdaBoost_cm,\n",
    "    \"Random Forest Classifier\": RFC_cm,\n",
    "}\n",
    "\n",
    "fig, axn = plt.subplots(1,6, sharex=True, sharey=True,figsize=(40,5))\n",
    "\n",
    "for i, ax in enumerate(axn.flat):\n",
    "    k = list(classifiers)[i]\n",
    "    sns.heatmap(classifiers[k], ax=ax, cbar=i==5, annot=True, cmap='Blues')\n",
    "    ax.set_title(k,fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2470903c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision - Bf</th>\n",
       "      <th>Precision - Af</th>\n",
       "      <th>Accuracy - Bf</th>\n",
       "      <th>Accuracy - Af</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KN Neighbour</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.659341</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.674242</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.690722</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.734848</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier  Precision - Bf  Precision - Af  Accuracy - Bf  \\\n",
       "0             AdaBoost        1.000000        1.000000       1.000000   \n",
       "3         KN Neighbour        0.800000        1.000000       0.818182   \n",
       "4        Random Forest        0.905405        0.896104       0.909091   \n",
       "5       Neural Network        0.659341        0.871429       0.674242   \n",
       "2                  SVM        0.690722        0.837500       0.734848   \n",
       "1  Logistic Regression        0.739130        0.728571       0.704545   \n",
       "\n",
       "   Accuracy - Af  \n",
       "0       1.000000  \n",
       "3       1.000000  \n",
       "4       0.916667  \n",
       "5       0.848485  \n",
       "2       0.863636  \n",
       "1       0.696970  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ['AdaBoost','Logistic Regression','SVM','KN Neighbour','Random Forest','Neural Network']\n",
    "metrices = pd.DataFrame(zip(X, pre_optimization_precision,post_optimization_precision,\n",
    "                            pre_optimization_accuracy, post_optimization_accuracy),\n",
    "                        columns=['Classifier','Precision - Bf','Precision - Af','Accuracy - Bf','Accuracy - Af'])\n",
    "\n",
    "metrices = metrices.sort_values('Precision - Af',ascending=False)\n",
    "metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1efced67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_axis = np.arange(len(metrices))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(X_axis - 0.2, metrices['Precision - Af'] * 100, 0.4, label = 'Post Hyperparameter Tuning')\n",
    "plt.bar(X_axis + 0.2, metrices['Precision - Bf'] * 100, 0.4, label = 'Pre Hyperparameter Tuning',\n",
    "        color='lightblue')\n",
    "\n",
    "plt.xticks(X_axis, metrices['Classifier'])\n",
    "plt.title(\"Model Tuning - Precision\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4da1f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrices = metrices.sort_values('Accuracy - Af',ascending=False)\n",
    "  \n",
    "X_axis = np.arange(len(metrices))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(X_axis - 0.2, metrices['Accuracy - Af'] * 100, 0.4, label = 'Post Hyperparameter Tuning')\n",
    "plt.bar(X_axis + 0.2, metrices['Accuracy - Bf'] * 100, 0.4, label = 'Pre Hyperparameter Tuning',color='lightblue')\n",
    "  \n",
    "plt.xticks(X_axis, metrices['Classifier'])\n",
    "plt.title(\"Model Tuning - Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ffd76ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import DetCurveDisplay, RocCurveDisplay\n",
    "\n",
    "classifiers = {\n",
    "    \"Logisitic Regression\": LogReg_search,\n",
    "    \"KNearest\": KNN_search,\n",
    "    \"Support Vector Classifier\": svm_search,\n",
    "    \"AdaBoost\": AdaBoost_search,\n",
    "    \"Random Forest Classifier\": RFC_search,\n",
    "    \"Neural Network\": NN_search\n",
    "}\n",
    "\n",
    "# prepare plots\n",
    "fig, ax_roc = plt.subplots(1, 1, figsize=(15, 8))\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "\n",
    "    try:\n",
    "        RocCurveDisplay.from_estimator(clf, X_test, y_test, ax=ax_roc, name=name)\n",
    "        #DetCurveDisplay.from_estimator(clf, X_test, y_test, ax=ax_det, name=name)\n",
    "    except ValueError:\n",
    "        RocCurveDisplay.from_predictions(y_pred=NN_pred, y_true=y_test, ax=ax_roc, name=name)\n",
    "        #DetCurveDisplay.from_predictions(y_pred=NN_pred, y_true=y_test, ax=ax_det, name=name)        \n",
    "\n",
    "ax_roc.set_title(\"Receiver Operating Characteristic (ROC) curves\")\n",
    "#ax_det.set_title(\"Detection Error Tradeoff (DET) curves\")\n",
    "\n",
    "ax_roc.grid(linestyle=\"--\")\n",
    "#ax_det.grid(linestyle=\"--\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
